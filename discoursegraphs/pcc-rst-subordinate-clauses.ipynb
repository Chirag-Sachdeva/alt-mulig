{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import discoursegraphs as dg\n",
    "from discoursegraphs.corpora import pcc\n",
    "from discoursegraphs.readwrite.rst import rs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 1: Which syntactic subordinate clauses match with an RST EDU?\n",
    "## Task 2: Are these EDUs satellites or nucleii?\n",
    "## Task 3: does this correlate with certain RST relation types?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subordinate_clauses(tiger_docgraph):\n",
    "    \"\"\"\n",
    "    given a document graph of a TIGER syntax tree, return all\n",
    "    node IDs of nodes representing subordinate clause constituents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tiger_docgraph : dg.DiscourseDocumentGraph\n",
    "        document graph from which subordinate clauses will be extracted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    subord_clause_nodes : list(str)\n",
    "        list of node IDs of nodes directly dominating subordinate clauses\n",
    "    \"\"\"\n",
    "    subord_clause_rels = \\\n",
    "        dg.select_edges_by_attribute(\n",
    "            tiger_docgraph, attribute='tiger:label',\n",
    "            value=['MO', 'RC', 'SB'])\n",
    "    \n",
    "    subord_clause_nodes = []\n",
    "    for src_id, target_id in subord_clause_rels:\n",
    "        src_cat = tiger_docgraph.node[src_id].get('tiger:cat')\n",
    "        if src_cat == 'S' and not dg.istoken(tiger_docgraph, target_id):\n",
    "            subord_clause_nodes.append(target_id)\n",
    "    return subord_clause_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from intervaltree import IntervalTree, Interval\n",
    "\n",
    "import discoursegraphs as dg\n",
    "from discoursegraphs.readwrite.rst import rs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _spans2nodes(docgraph, nodes):\n",
    "    \"\"\"\n",
    "    Takes a document graph and a collection of nodes\n",
    "    and returns a mapping from a span to all the nodes\n",
    "    that dominate that span. (There might be multiple\n",
    "    nodes which cover the same span.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docgraph : dg.DiscourseDocumentGraph\n",
    "        document graph from which the span-node mapping will be extracted\n",
    "    nodes : collections.Iterable(str)\n",
    "        a list/collection of node IDs whose spans will be extracted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    span2nodes : defaultdict(tuple(int, int): list(str))\n",
    "        maps from the offsets of a span to a list of node IDs\n",
    "        (of nodes directly dominating that span)\n",
    "    \"\"\"\n",
    "    span2nodes = defaultdict(list)\n",
    "    for node_id in nodes:\n",
    "        span = dg.get_span_offsets(docgraph, node_id)\n",
    "        span2nodes[span].append(node_id)\n",
    "    return span2nodes\n",
    "\n",
    "def get_max_overlaps(overlap_map):\n",
    "    \"\"\"\n",
    "    finds the nodes with the longest overlapping span.\n",
    "    TODO: needs heavy refactoring, input/output is\n",
    "    hard to grasp.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    overlap_map : defaultdict(str: list(dict))\n",
    "        maps from a local node (node ID) to a list of other nodes,\n",
    "        where each other node is represented as a dict\n",
    "        with the keys ``node_id`` (str), ``overlap`` (float)\n",
    "        and ``interval`` (tuple(int, int))\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    max_overlapping_nodes : dict(str: dict)\n",
    "        maps from a local node (node ID str) to\n",
    "        the other node (dict with keys ``node_id`` (str),\n",
    "        ``overlap`` (float) and ``interval``\n",
    "        (tuple(int, int))) that has the greatest overlap\n",
    "        with it\n",
    "    \"\"\"\n",
    "    # given a list of other nodes, return the one\n",
    "    # with the highest overlap score\n",
    "    max_overlap = lambda l: sorted(\n",
    "        l, key=lambda n: n['overlap'],\n",
    "        reverse=True)[0]\n",
    "    return {local_node: max_overlap(overlap_map[local_node])\n",
    "            for local_node in overlap_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_overlap_scores(local_span, overlap_interval):\n",
    "    \"\"\"\n",
    "    calculates the overlap between the given input spans.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    local_span : tuple(int, int)\n",
    "        the onset and offset of the ``local`` span\n",
    "    overlap_interval : Interval\n",
    "        the onset and offset of the ``other`` span\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    overlap_ratio : float\n",
    "        the percentage of overlap between the input spans\n",
    "    len_overlap : the number of consecutive characters that\n",
    "        the input spans share\n",
    "    len_longest_input : length (in characters) of the longest\n",
    "        of the two input spans\n",
    "    \"\"\"\n",
    "    local_on, local_off = local_span\n",
    "    len_local = local_off - local_on\n",
    "\n",
    "    other_on, other_off = overlap_interval.begin, overlap_interval.end\n",
    "    len_other = other_off - other_on\n",
    "    len_longest_input = max(len_local, len_other)\n",
    "\n",
    "    overlap_on = max(local_on, other_on)\n",
    "    overlap_off = min(local_off, other_off)\n",
    "    # length of overlap in chars (int)\n",
    "    len_overlap = overlap_off - overlap_on\n",
    "\n",
    "    # overlap (float) in % between the input intervals\n",
    "    overlap_ratio = len_overlap / float(len_longest_input) * 100\n",
    "\n",
    "    return overlap_ratio, len_overlap, len_longest_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_overlapping_nodes(\n",
    "    docgraph, local_nodes, other_nodes,\n",
    "    overlap_threshold=95, debug=False, strict=False):\n",
    "    \"\"\"\n",
    "    given a document graph and two sets of nodes (called\n",
    "    ``local_nodes`` and ``other_nodes`` merely to distinguish them),\n",
    "    find pairs of nodes (one ``local`` and one ``other``) which\n",
    "    cover (approximately) the same span.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    docgraph : DiscourseDocumentGraph\n",
    "        the document graph in which we'll look for\n",
    "        overlapping nodes\n",
    "    local_nodes : collections.Iterable(str)\n",
    "        a collection of node IDs\n",
    "    other_nodes : collections.Iterable(str)\n",
    "        a collection of node IDs.\n",
    "        There's no technical difference between ``local_nodes``\n",
    "        and ``other_nodes``, we justed to distinguish the\n",
    "        two collections.\n",
    "    overlap_threshold : int\n",
    "        two spans are considered overlapping, if\n",
    "        their onset/offset intervals overlap at least N %\n",
    "    strict : bool\n",
    "        If True, the overlap has to pass the threshold. Otherwise,\n",
    "        up to two characters shorter than the longest input string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    max_overlapping_nodes : dict(str: dict)\n",
    "        maps from a local node (node ID str) to\n",
    "        the other node (dict with keys ``node_id`` (str),\n",
    "        ``overlap`` (float) and ``interval``\n",
    "        (tuple(int, int))) that has the greatest overlap\n",
    "        with it\n",
    "    \"\"\"    \n",
    "    def fulfills_overlap_criteria(strict, overlap, overlap_threshold,\n",
    "                                  len_overlap, len_longest_input):\n",
    "        \"\"\"\n",
    "        returns True, if the overlap criteria are met.\n",
    "\n",
    "        If strict is True, the overlap has to pass a threshold. Otherwise,\n",
    "        the length of the overlap is allowed to be up to two characters\n",
    "        shorter than the longest input string. (The strict=False option\n",
    "        is therefore useful for comparing short spans with potentially\n",
    "        diverging tokenization rules, e.g. 'Hello' vs. 'Hello !'.)\n",
    "        \"\"\"\n",
    "        if strict:\n",
    "            if overlap >= overlap_threshold:\n",
    "                return True\n",
    "        else:\n",
    "            if overlap >= overlap_threshold or (len_overlap+2 >= len_longest_input):\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    # there might be more than one node covering the same span,\n",
    "    # e.g. when an NP only consists of a single noun\n",
    "    local_span2nodes = _spans2nodes(docgraph, local_nodes)        \n",
    "    other_span2nodes = _spans2nodes(docgraph, other_nodes)\n",
    "\n",
    "    other_tree = IntervalTree.from_tuples(other_span2nodes.keys())\n",
    "    \n",
    "    # overlap_map : defaultdict(str: list(dict))\n",
    "    #    maps from a local node (node ID) to a list of other nodes,\n",
    "    #    where each other node is represented as a dict\n",
    "    #    with the keys ``node_id`` (str), ``overlap`` (float)\n",
    "    #    and ``interval`` (tuple(int, int))\n",
    "    overlap_map = defaultdict(list)\n",
    "\n",
    "    # local_span : tuple(int, int)\n",
    "    for local_span in local_span2nodes:\n",
    "        # overlap_intervals : set(Interval)\n",
    "        # all the spans from ``other_spans`` that overlap with this ``local_span``\n",
    "        overlap_intervals = other_tree[Interval(*local_span)]\n",
    "        for overlap_interval in overlap_intervals:\n",
    "            overlap, len_overlap, len_longest_input = \\\n",
    "                get_overlap_scores(local_span, overlap_interval)\n",
    "            \n",
    "            if fulfills_overlap_criteria(strict, overlap, overlap_threshold,\n",
    "                                         len_overlap, len_longest_input):\n",
    "                other_on, other_off = overlap_interval.begin, overlap_interval.end\n",
    "                # generate a mapping from a local node (node ID str)\n",
    "                # to all the ``other_nodes`` it overlaps with (incl.\n",
    "                # their overlap in % for finding the best match)\n",
    "                for local_node in local_span2nodes[local_span]:\n",
    "                    overlap_span = (other_on, other_off)\n",
    "                    for other_node in other_span2nodes[overlap_span]:\n",
    "                        overlap_map[local_node].append(\n",
    "                            {'node_id': other_node, 'overlap': overlap,\n",
    "                             'interval': (other_on, other_off)})\n",
    "    \n",
    "    return get_max_overlaps(overlap_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rst_subord_matches(document_ids=None):\n",
    "    \"\"\"find all subordinate clauses that match with an EDU.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    document_ids : list(str) or None\n",
    "        A list of document IDs. Iff None, extract matches\n",
    "        from the complete PCC.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matches : list(tuple(str, str, str))\n",
    "        A list of spans that cover both an RST EDU as well as a\n",
    "        subordinate clause. Each span is represented as a\n",
    "        (subordinate clause type, RST segment type, RST relation name)\n",
    "        tuple, e.g. ('NP', 'nucleus', 'elaboration').\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    if document_ids is None:\n",
    "        document_ids = pcc.document_ids\n",
    "    \n",
    "    for doc_id in document_ids:\n",
    "        docgraph = pcc[doc_id]\n",
    "\n",
    "        # compare subordinate clauses to EDUs\n",
    "        subord_nodes = get_subordinate_clauses(docgraph)\n",
    "        edu_nodes =  rs3.get_edus(docgraph)\n",
    "\n",
    "        overlapping_nodes_map = find_overlapping_nodes(\n",
    "            docgraph, subord_nodes, edu_nodes, overlap_threshold=100, debug=True, strict=False)\n",
    "\n",
    "        for subord_id, edu in overlapping_nodes_map.items():\n",
    "            subord_clause_cat = docgraph.node[subord_id]['tiger:cat']\n",
    "\n",
    "            edu_node_id = edu['node_id']\n",
    "            segment_type = docgraph.node[edu_node_id]['rst:segment_type']\n",
    "\n",
    "            rel_name = docgraph.node[edu_node_id].get('rst:rel_name')\n",
    "            if not rel_name: # try to get the rel_name, no matter what (cf. issue #139)\n",
    "                in_edges = docgraph.in_edges(edu_node_id)\n",
    "                assert len(in_edges) == 1, \\\n",
    "                    \"There must be exactly one dominating node.\"\n",
    "                dom_node_id = in_edges[0][0]\n",
    "                rel_name = docgraph.node[dom_node_id]['rst:rel_name']\n",
    "\n",
    "            # prints the subordinating clause and the EDU that it matches\n",
    "    #         print subord_clause_cat, edu_node_id, segment_type, rel_name\n",
    "            matches.append((subord_clause_cat, segment_type, rel_name))\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset_doc_ids = ['maz-3277', 'maz-3377', 'maz-4428', 'maz-10110', 'maz-19436']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = get_rst_subord_matches()\n",
    "subset_matches = get_rst_subord_matches(subset_doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = DataFrame(matches, columns=('clause', 'segment', 'relation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many subordinate clauses are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3279\n"
     ]
    }
   ],
   "source": [
    "# in the PCC\n",
    "subord_clauses = []\n",
    "for doc_id in pcc.document_ids:\n",
    "    docgraph = pcc[doc_id]\n",
    "    subord_clauses.extend(get_subordinate_clauses(docgraph))\n",
    "print len(subord_clauses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# in the subcorpus\n",
    "subord_clauses = []\n",
    "for doc_id in subset_doc_ids:\n",
    "    docgraph = pcc[doc_id]\n",
    "    subord_clauses.extend(get_subordinate_clauses(docgraph))\n",
    "print len(subord_clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many EDUs are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUs: 3018\n",
      "nucleii: 1395\n",
      "satellites: 1117\n"
     ]
    }
   ],
   "source": [
    "# in the PCC\n",
    "edus = []\n",
    "nucleii = []\n",
    "satellites = []\n",
    "for doc_id in pcc.document_ids:\n",
    "    docgraph = pcc[doc_id]\n",
    "    edu_nodes = rs3.get_edus(docgraph)\n",
    "    edus.extend(edu_nodes)\n",
    "    for edu_node_id in edu_nodes:\n",
    "        segment_type = docgraph.node[edu_node_id]['rst:segment_type']\n",
    "        if segment_type == 'nucleus':\n",
    "            nucleii.append(edu_node_id)\n",
    "        elif segment_type == 'satellite':\n",
    "            satellites.append(edu_node_id)\n",
    "\n",
    "print 'EDUs:', len(edus)\n",
    "print 'nucleii:', len(nucleii)\n",
    "print 'satellites:', len(satellites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "with codecs.open('/tmp/edus_in_pcc.txt', 'w', encoding='utf8') as edu_file:\n",
    "    for doc_id in pcc.document_ids:\n",
    "        docgraph = pcc[doc_id]\n",
    "        edu_nodes = rs3.get_edus(docgraph)\n",
    "        edus.extend(edu_nodes)\n",
    "        for edu_node_id in edu_nodes:\n",
    "            segment_type = docgraph.node[edu_node_id]['rst:segment_type']\n",
    "            edu_file.write(u\"({}, {}, {})\\n\".format(doc_id, edu_node_id, docgraph.node[edu_node_id]['rst:text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUs: 89\n",
      "nucleii: 36\n",
      "satellites: 39\n"
     ]
    }
   ],
   "source": [
    "# in the subcorpus\n",
    "edus = []\n",
    "nucleii = []\n",
    "satellites = []\n",
    "for doc_id in subset_doc_ids:\n",
    "    docgraph = pcc[doc_id]\n",
    "    edu_nodes = rs3.get_edus(docgraph)\n",
    "    edus.extend(edu_nodes)\n",
    "    for edu_node_id in edu_nodes:\n",
    "        segment_type = docgraph.node[edu_node_id]['rst:segment_type']\n",
    "        if segment_type == 'nucleus':\n",
    "            nucleii.append(edu_node_id)\n",
    "        elif segment_type == 'satellite':\n",
    "            satellites.append(edu_node_id)\n",
    "\n",
    "print 'EDUs:', len(edus)\n",
    "print 'nucleii:', len(nucleii)\n",
    "print 'satellites:', len(satellites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many matching spans are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print len(matches) # in the PCC\n",
    "print len(subset_matches) # in the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.segment == 'satellite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.segment == 'nucleus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clause</th>\n",
       "      <th>segment</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>S</td>\n",
       "      <td>span</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>S</td>\n",
       "      <td>span</td>\n",
       "      <td>concession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>S</td>\n",
       "      <td>span</td>\n",
       "      <td>cause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>S</td>\n",
       "      <td>span</td>\n",
       "      <td>antithesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>S</td>\n",
       "      <td>span</td>\n",
       "      <td>antithesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>S</td>\n",
       "      <td>span</td>\n",
       "      <td>condition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clause segment    relation\n",
       "102      S    span   condition\n",
       "120      S    span  concession\n",
       "142      S    span       cause\n",
       "148      S    span  antithesis\n",
       "182      S    span  antithesis\n",
       "190      S    span   condition"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.segment != 'nucleus') & (df.segment != 'satellite')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: different definitions of overlap\n",
    "\n",
    "- I implemented overlap based on string overlap\n",
    "  - a clause and an EDU match, if they cover the same range of characters  \n",
    "    (+/- 2 characters)\n",
    "- W. implemented overlap in neo4j based on token overlap\n",
    "  - a clause and an EDU match, if they cover the same tokens (+/- 2 tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: implement token overlap for discoursegraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_token_based_rst_subord_matches(document_ids=None):\n",
    "    \"\"\"find all subordinate clauses that match with an EDU.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    document_ids : list(str) or None\n",
    "        A list of document IDs. Iff None, extract matches\n",
    "        from the complete PCC.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matches : list(tuple(str, str, str))\n",
    "        A list of spans that cover both an RST EDU as well as a\n",
    "        subordinate clause. Each span is represented as a\n",
    "        (subordinate clause type, RST segment type, RST relation name)\n",
    "        tuple, e.g. ('NP', 'nucleus', 'elaboration').\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    subord_node_tokens = defaultdict(dict)\n",
    "    edu_node_tokens = defaultdict(dict)\n",
    "    \n",
    "    if document_ids is None:\n",
    "        document_ids = pcc.document_ids\n",
    "    \n",
    "    for doc_id in document_ids:\n",
    "        docgraph = pcc[doc_id]\n",
    "\n",
    "        # compare subordinate clauses to EDUs\n",
    "        subord_nodes = get_subordinate_clauses(docgraph)\n",
    "        edu_nodes =  rs3.get_edus(docgraph)\n",
    "#         print 'doc_id:', doc_id, 'num of edus:', len(edu_nodes)\n",
    "        \n",
    "        for subord_node in subord_nodes:\n",
    "            subord_node_tokens[doc_id][subord_node] = set(dg.get_span(docgraph, subord_node))\n",
    "        \n",
    "        for edu_node in edu_nodes:\n",
    "            edu_node_tokens[doc_id][edu_node] = set(dg.get_span(docgraph, edu_node))\n",
    "    return subord_node_tokens, edu_node_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subord_node_map, edu_node_map = get_token_based_rst_subord_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "print len(subord_node_map)\n",
    "print len(edu_node_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo[23][42] = 'bar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{42: 'bar'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = defaultdict(lambda : defaultdict(set))\n",
    "\n",
    "for doc_id in subord_node_map:\n",
    "    for subord_node_id in subord_node_map[doc_id]:\n",
    "        subord_token_set = subord_node_map[doc_id][subord_node_id]\n",
    "        num_subord_tokens = len(subord_token_set)\n",
    "        \n",
    "        for edu_node_id, edu_token_set in edu_node_map[doc_id].iteritems():\n",
    "            num_common_tokens = len(subord_token_set.intersection(edu_token_set))\n",
    "            if num_common_tokens > 0 and \\\n",
    "                num_common_tokens in range(num_subord_tokens-1, num_subord_tokens+2):\n",
    "#                     print doc_id, subord_node_id, edu_node_id\n",
    "                    matches[doc_id][subord_node_id].add(edu_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: write generic histogram function\n",
    "\n",
    "print(len(matches))\n",
    "matches.items()[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: what's wrong with this matching\n",
    "\n",
    "```\n",
    " ('maz-13125',\n",
    "  defaultdict(set,\n",
    "              {'s384_502': {'rst:11', 'rst:4'},\n",
    "               's384_510': {'rst:11', 'rst:4'},\n",
    "               's386_504': {'rst:12', 'rst:4'},\n",
    "               's388_500': {'rst:10', 'rst:4'},\n",
    "               's389_502': {'rst:10', 'rst:4', 'rst:5', 'rst:6'},\n",
    "               's391_502': {'rst:7'},\n",
    "               's391_512': {'rst:7'},\n",
    "               's394_500': {'rst:8'},\n",
    "               's394_502': {'rst:16', 'rst:8'},\n",
    "               's394_505': {'rst:8'},\n",
    "               's394_508': {'rst:16', 'rst:8'},\n",
    "               's395_500': {'rst:9'}})),\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maz_13125_s389_str = \"\"\"\n",
    "<s xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" id=\"s389\" art_id=\"13125\" orig_id=\"ID_maz-13125\">\n",
    "<graph root=\"s389_503\">\n",
    "<terminals>\n",
    "<t id=\"s389_1\" word=\"Was\" lemma=\"--\" pos=\"PWS\" morph=\"--\"/>\n",
    "<t id=\"s389_2\" word=\"man\" lemma=\"--\" pos=\"PIS\" morph=\"--\"/>\n",
    "<t id=\"s389_3\" word=\"nicht\" lemma=\"--\" pos=\"PTKNEG\" morph=\"--\"/>\n",
    "<t id=\"s389_4\" word=\"durch\" lemma=\"--\" pos=\"APPR\" morph=\"--\"/>\n",
    "<t id=\"s389_5\" word=\"Augenschein\" lemma=\"--\" pos=\"NN\" morph=\"--\"/>\n",
    "<t id=\"s389_6\" word=\"nachprüfen\" lemma=\"--\" pos=\"VVINF\" morph=\"--\"/>\n",
    "<t id=\"s389_7\" word=\"kann\" lemma=\"--\" pos=\"VMFIN\" morph=\"--\"/>\n",
    "<t id=\"s389_8\" word=\",\" lemma=\"--\" pos=\"$,\" morph=\"--\"/>\n",
    "<t id=\"s389_9\" word=\"ist\" lemma=\"--\" pos=\"VAFIN\" morph=\"--\"/>\n",
    "<t id=\"s389_10\" word=\"manipulierbar\" lemma=\"--\" pos=\"ADJD\" morph=\"--\"/>\n",
    "<t id=\"s389_11\" word=\".\" lemma=\"--\" pos=\"$.\" morph=\"--\"/>\n",
    "</terminals>\n",
    "<nonterminals>\n",
    "<nt id=\"s389_500\" cat=\"PP\">\n",
    "<edge label=\"AC\" idref=\"s389_4\"/>\n",
    "<edge label=\"NK\" idref=\"s389_5\"/>\n",
    " </nt>\n",
    "<nt id=\"s389_501\" cat=\"VP\">\n",
    "<edge label=\"OA\" idref=\"s389_1\"/>\n",
    "<edge label=\"HD\" idref=\"s389_6\"/>\n",
    "<edge label=\"MO\" idref=\"s389_500\"/>\n",
    " </nt>\n",
    "<nt id=\"s389_502\" cat=\"S\">\n",
    "<edge label=\"SB\" idref=\"s389_2\"/>\n",
    "<edge label=\"NG\" idref=\"s389_3\"/>\n",
    "<edge label=\"HD\" idref=\"s389_7\"/>\n",
    "<edge label=\"OC\" idref=\"s389_501\"/>\n",
    " </nt>\n",
    "<nt id=\"s389_503\" cat=\"S\">\n",
    "<edge label=\"HD\" idref=\"s389_9\"/>\n",
    "<edge label=\"PD\" idref=\"s389_10\"/>\n",
    "<edge label=\"SB\" idref=\"s389_502\"/>\n",
    " </nt>\n",
    "</nonterminals>\n",
    "</graph>\n",
    "</s>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import discoursegraphs as dg\n",
    "\n",
    "maz_13125_s389 = etree.fromstring(maz_13125_s389_str)\n",
    "tsg = dg.readwrite.tiger.TigerSentenceGraph(maz_13125_s389)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext gvmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%dotstr dg.print_dot(tsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dg.print_dot(tsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = u\"\"\"\n",
    "digraph \"\" {\n",
    "\n",
    "\"discoursegraph:root_node\";\n",
    "\"VROOT-s389\";\n",
    "\"s389_500\" [label=\"PP\"];\n",
    "\"s389_501\" [label=\"VP\"];\n",
    "\"s389_502\" [label=\"S\"];\n",
    "\"s389_503\" [label=\"S\"];\n",
    "\n",
    "\"s389_1\" [label=\"Was\"];\n",
    "\"s389_2\" [label=\"man\"];\n",
    "\"s389_3\" [label=\"nicht\"];\n",
    "\"s389_4\" [label=\"durch\"];\n",
    "\"s389_5\" [label=\"Augenschein\"];\n",
    "\"s389_6\" [label=\"nachprüfen\"];\n",
    "\"s389_7\" [label=\"kann\"];\n",
    "\"s389_8\" [label=\",\"];\n",
    "\"s389_9\" [label=\"ist\"];\n",
    "\"s389_10\" [label=\"manipulierbar\"];\n",
    "\"s389_11\" [label=\".\"];\n",
    "\n",
    "edge [style=\"invis\"];\n",
    "{rank=same; \"s389_1\" -> \"s389_2\" -> \"s389_3\" -> \"s389_4\" -> \"s389_5\" -> \"s389_6\" -> \"s389_7\" -> \"s389_8\" -> \"s389_9\" -> \"s389_10\" -> \"s389_11\";}\n",
    "edge [style=\"\"];\n",
    "\n",
    "\"discoursegraph:root_node\" -> \"VROOT-s389\" [key=0]; // changed direction\n",
    "\n",
    "\"s389_501\" -> \"s389_6\"  [key=0, label=\"HD\"];\n",
    "\"s389_501\" -> \"s389_1\"  [key=0, label=\"OA\"];\n",
    "\"s389_501\" -> \"s389_500\"  [key=0, label=\"MO\"];\n",
    "\"s389_500\" -> \"s389_5\"  [key=0, label=\"NK\"];\n",
    "\"s389_500\" -> \"s389_4\"  [key=0, label=\"AC\"];\n",
    "\"s389_503\" -> \"s389_9\"  [key=0, label=\"HD\"];\n",
    "\"s389_503\" -> \"s389_10\"  [key=0, label=\"PD\"];\n",
    "\"s389_503\" -> \"s389_502\"  [key=0, label=\"SB\"];\n",
    "\"s389_502\" -> \"s389_2\"  [key=0, label=\"SB\"];\n",
    "\"s389_502\" -> \"s389_3\"  [key=0, label=\"NG\"];\n",
    "\"s389_502\" -> \"s389_501\"  [key=0, label=\"OC\"];\n",
    "\"s389_502\" -> \"s389_7\"  [key=0, label=\"HD\"];\n",
    "\"VROOT-s389\" -> \"s389_503\"  [key=0];\n",
    "\n",
    "\"VROOT-s389\" -> \"s389_8\"  [key=0];\n",
    "\"VROOT-s389\" -> \"s389_11\"  [key=0];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "%dotstr foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches[('maz-8838', 's2013_501')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ab = b.intersection(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "range(len(a)-1, len(a)+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: not even subord. clause counts match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parents_of_subordinate_clauses(tiger_docgraph):\n",
    "    parents = []\n",
    "    subord_clause_rels = \\\n",
    "        dg.select_edges_by_attribute(\n",
    "            tiger_docgraph, attribute='tiger:label',\n",
    "            value=['MO', 'RC', 'SB'])\n",
    "    \n",
    "#     subord_clause_nodes = []\n",
    "    for src_id, target_id in subord_clause_rels:\n",
    "        src_cat = tiger_docgraph.node[src_id].get('tiger:cat')\n",
    "        if src_cat == 'S' and not dg.istoken(tiger_docgraph, target_id):\n",
    "#             subord_clause_nodes.append(target_id)\n",
    "            parents.append(src_id)\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for doc_id in pcc.document_ids:\n",
    "#     docgraph = pcc[doc_id]\n",
    "#     print 'doc_id:', doc_id\n",
    "#     parents = get_parents_of_subordinate_clauses(docgraph)\n",
    "#     print parents, '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_numeric = df.copy()\n",
    "\n",
    "encoders = {} # keep them for decoding the data later\n",
    "for colname in df.columns:\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoders[colname] = encoder\n",
    "    df_numeric[colname] = encoder.fit_transform(df[colname])\n",
    "\n",
    "#to convert back\n",
    "\n",
    "# train.Sex = le_sex.inverse_transform(train.Sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_numeric['clause'] = encoders['clause'].inverse_transform(df_numeric['clause'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df.clause).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df.segment).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([pd.get_dummies(df.clause).head(), pd.get_dummies(df.segment).head()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext gvmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_column(df, target_column, feature_columns=None, max_depth=5, min_samples_leaf=2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # convert all feature cols w/ get_dummies & concat them\n",
    "    if feature_columns is None:\n",
    "        train_df = df.drop(labels=[target_column], axis=1)\n",
    "    else:\n",
    "        train_df = DataFrame(df, columns=feature_columns)\n",
    "        \n",
    "    train_binarized = pd.concat(\n",
    "        (pd.get_dummies(df[col]) for col in train_df.columns), axis=1)\n",
    "    \n",
    "    target_series = df[target_column]\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
    "    dt.fit(train_binarized, target_series)\n",
    "    return dt, train_binarized, target_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "\n",
    "# # df.drop(labels=['clause'], axis=1)\n",
    "# for colname in df.columns:\n",
    "#     dt, train_binarized, target_series = predict_column(df, colname)\n",
    "\n",
    "#     out = StringIO()\n",
    "#     export_graphviz(dt, out_file=out)\n",
    "#     %dotstr out.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt, train_binarized, target_series = predict_column(\n",
    "    df, target_column='segment', feature_columns=['clause'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = StringIO()\n",
    "export_graphviz(dt, out_file=out,\n",
    "                feature_names=train_binarized.columns,  \n",
    "                class_names=dt.classes_, \n",
    "                filled=True, rounded=True,  \n",
    "                special_characters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DictVectorizer usage example\n",
    "\n",
    "## if we can't use pandas.get_dummies() ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clause_df = df[['clause']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clause_df.head().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clause_df.T.to_dict().values()[:10]\n",
    "clause_dict = clause_df.T.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "vectorizer = DV( sparse = False )\n",
    "clause_vec = vectorizer.fit_transform(clause_dict)\n",
    "clause_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('clause-segment-relation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%dotstr out.getvalue()\n",
    "# train_binarized.columns\n",
    "# target_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TODO: try Frequent Itemset visualization\n",
    "\n",
    "- Grouped matrix-based visualization\n",
    "- available in ``arulesViz`` R-package\n",
    "- cf. Hahsler and Chelluboina (2011). Visualizing Association Rules in Hierarchical Groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
