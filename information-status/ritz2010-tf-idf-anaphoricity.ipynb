{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ritz, Julia (2010). Using tf-idf-related Measures for Determining the Anaphoricity of Noun Phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "- test suitability of tf-idf-based measures for  \n",
    "  classifying discourse-given vs. discourse-new NPs  \n",
    "  (a.k.a. **anaphoricity**)\n",
    "- test corpora : ... (English newswire)\n",
    "- results: significant, w/out relying on language-specific  \n",
    "  resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "- tf-idf is a shallow semantic measure i.a. used in information retrieval  \n",
    "  and text summarization\n",
    "- **anaphoricity**: an NP is anaphoric if it refers to a real-workd entity  \n",
    "  mentioned in the preceding text\n",
    "- **usage**: anaphoricity classification as a first step in anaphora resolution  \n",
    "  (i.e. reducing the search space)\n",
    " \n",
    "## Challenges\n",
    "- matching anaphora-antecedent pairs is hard\n",
    "- **previous attempts**: matching complete NP strings or only their heads,  \n",
    "  first or last tokens, etc.\n",
    "- these methods all rely on token boundaries and therefore can't account for  \n",
    "  **compounding** (``Berlin`` vs. ``the Berlin-based startup``),  \n",
    "  **derivation** (e.g. event anaphors ``canceled`` vs. ``the cancellation``) and  \n",
    "  **name variations**\n",
    "\n",
    "## proposed solution\n",
    "\n",
    "- tf-idf-based matching between NPs, where terms are character ngrams  \n",
    "  (here: 4-grams, as suggested by Taboada et al. (2009))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf adapted for anaphoricity classification\n",
    "\n",
    "- for each NP, we calculate a set of tf-idf-based features:\n",
    "\n",
    "\n",
    "\n",
    "* $t$: term / character ngram\n",
    "* $d$: document\n",
    "* $D$: corpus / set of documents\n",
    "* $D_t$: set of documents containing term *t*\n",
    "* $tf_{t,d}$: number of times term *t* occurs in document *d*,  \n",
    "  normalized to the total number of terms in the document\n",
    "\n",
    "## tf-idf\n",
    "\n",
    "$tf idf_{t,d} = tf_{t,d} * \\log(\\frac{|D|}{|D_{t}|})$\n",
    "\n",
    "## anaphoricity classification\n",
    "\n",
    "- partition the text before the NP to classify\n",
    "  * $d_1, ..., d_n$: characters in document *D*\n",
    "  * if an NP starts at $x_{k+1}$, then ...\n",
    "  * $tf_{t,d_{k}}$ is the relative frequency of term *t* in $d_k$  \n",
    "  (document *d* up to position *k*)\n",
    "\n",
    "* $tf_{t,\\bar{d_k}} = tf_{t,d} - tf_{t,d_k}$\n",
    "  * read:  increase of *tf* after k = term count in doc - term count up to k\n",
    "  \n",
    "### we calculate the *sum* and *means* of these measures for each NP\n",
    "\n",
    "* $tf_{t,d}$: how often occurs t in d?\n",
    "* $tf_{t,d_k}$: how often occurs t in d up to position k?\n",
    "* $tf_{t,\\bar{d_k}}$: how often occurs t in d after position k?\n",
    "* $tf idf_{t,d}$: \"standard\" tf-idf (for the whole document d)\n",
    "* $tf idf_{t,d_k}$: tf-idf for document d up to position k\n",
    "* $tf idf_{t,\\bar{d_k}}$: tf-idf for document after position k\n",
    "* $idf$: \"standard\" (idf)\n",
    "\n",
    "To calculate the sum across an NP, do this:\n",
    "\n",
    "* $NP^{e}_s$: an NP starting at position *s* and ending at position *e*\n",
    "* $l$: term / character ngram length (here: 4)\n",
    "\n",
    "$$S_{tf idf_{NP_s^{e}, d_s}} = \\sum_{i=s}^{e-l+1} tf idf_{t_i, d_i}$$\n",
    "\n",
    "* calculating the tf-idf means across an NP is e.g. used to  \n",
    "  determine the relevance of a sentence in text summarization (Bieler and Dipper 2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Experiments\n",
    "\n",
    "## Corpus & Annotation Scheme\n",
    "\n",
    "* test corpus: **WSJ section of OntoNotes**\n",
    "* annotation scheme:\n",
    "  - *APPOS*: linking attributive/appositive NPs\n",
    "  - *IDENT*: (other) coreference links\n",
    "* extracted all NPs with *IDENT* relation\n",
    "  * marked them as anaphoric (*AN*), if they had an antecedent,  \n",
    "    i.e. an expression to its left referring to the same ID\n",
    "  * otherwise marked as non-anaphoric (*NON*)\n",
    "\n",
    "## Preprocessing and Settings\n",
    "\n",
    "- random split: training and evaluation set,  \n",
    "  controlled by number of NPs in each document\n",
    "- **Train**: 103,245 NPs\n",
    "- **Test**: 13,414 NPs\n",
    "- subset of the data only including NNPs (proper names)\n",
    "- lemmatization using **TreeTagger**\n",
    "\n",
    "### features (to compare against tf-idf)\n",
    "\n",
    "* **exact** match (string identity): how many times has the exact same NP been mentioned before\n",
    "* matching **head**: how many times did the lemma of the NP's head occur \"in the lemmatized context\" ???\n",
    "  - head: rightmost token directly dominated by the NP node\n",
    "* NP's grammatical function (subj, adverbial NP etc)\n",
    "* NP's surface form (pronoun, def. det., indef. det, etc.)\n",
    "  - why is this called surface form?\n",
    "* bool: does NP contain a name (NNP)\n",
    "* in case of pronouns: morph. features (person, num, gender, reflexivity)\n",
    "\n",
    "## Classification Experiments and Results\n",
    "\n",
    "- **C4.5 decision trees** trained with **WEKA** (training set)\n",
    "- **baseline**: majority class (*NON*) $\\rightarrow$ 86.37% acc\n",
    "- **results**: significant improvement in acc. with each added feature set \n",
    "  - exact + head + tf-idf feats. + linguistic feats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```perl\n",
    "#1st pass\n",
    "l:=4; #initialize term length l\n",
    "D:=0; #initialize file counter D\n",
    "\n",
    "for each Document d i in the corpus\n",
    "#count document\n",
    "D++;\n",
    "p:=1; #initialize character position p\n",
    "    while p + l in d i\n",
    "        #sequentially cut into terms t of length l\n",
    "        t:=substring(d i , p, l);\n",
    "        #*insert string normalization (optional)*\n",
    "        #initialize count array where necessary\n",
    "        C(t, d i ):=0 unless defined;\n",
    "        #save number of previous mentions\n",
    "        #(i.e. annotate t with C(t, d i ))\n",
    "        A(t, d i , p):=C(t, d i );\n",
    "        #count current mention\n",
    "        C(t, d i )++;\n",
    "        #count documents containing t\n",
    "        #(only on first mention of t)\n",
    "        E(t)++ if (C(t, d i ) =1);\n",
    "        p++;\n",
    "    end; #end while\n",
    "end; #end for each;\n",
    "\n",
    "\n",
    "#2nd pass\n",
    "for each Document d i in the corpus\n",
    "    for each noun phrase NP s e in d i\n",
    "        sum:=0; #initialize sum\n",
    "        #from NP’s starting position. . .\n",
    "        p:=s;\n",
    "        #. . . to start of last term\n",
    "        while p <= e − l + 1\n",
    "            t:=substring(d i , p, l);\n",
    "            #*insert string normalization (optional)*\n",
    "            #get annotation of t at p,\n",
    "            #calculate tf-idf from it\n",
    "            #and add it to the current sum\n",
    "            sum+=(get(t, d i , p)/p)*log(D/E(t));\n",
    "            #calculate sum of other measures\n",
    "            ...\n",
    "        end; #end while\n",
    "\n",
    "        #average by the number of terms in NP s e\n",
    "        a:=sum/(e − s − l + 2);\n",
    "        #annotate sum and means to NP s e\n",
    "        S(d i , s, e):=sum;\n",
    "        M (d i , s, e):=a;\n",
    "    end; #end for each\n",
    "end; #end for each\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
