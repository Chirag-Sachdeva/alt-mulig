{
 "metadata": {
  "name": "",
  "signature": "sha256:e47c8e58553928b0ac13f8f40803fb1ec3a7bf3519516286304d70e7c8b91eaf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "parse RST-DT documents in LISP/S-Expression format"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* RST-DT *.rs3 files are broken, cf. my notebook on [RST-DT/PTB merging](rstdt-ptb-merging.ipynb)\n",
      "* **only use the `*.dis` files**, the `*.lisp.name` and `*.step.name` may be broken, too\n",
      "* the RST-DT people probably used [Marcu's tools](http://www.isi.edu/~marcu/discourse/utilities/index.html)  \n",
      "  to convert their annotations into *.dis format\n",
      "\n",
      "The RST Discourse Treebank contains 385 WSJ articles from PTB with Rhetorical Structure Theory (RST) annotations.\n",
      "\n",
      "The following information was taken from the RST-DT documentation:\n",
      "\n",
      "## RSTtrees-WSJ-main-1.0\n",
      "This directory contains 385 Wall Street Journal articles, broken into TRAINING (347 documents) and TEST (38 documents) sub-directories.\n",
      "\n",
      "Filenames are in one of two forms:\n",
      "* wsj_####.ext (380 documents)\n",
      "* file#.ext(5 documents)\n",
      "\n",
      "The 5 files named file# were identified as the following filenames in Treebank-2:\n",
      "\n",
      "* file1 - 07/wsj_0764\n",
      "* file2 - 04/wsj_0430\n",
      "* file3 - 07/wsj_0766\n",
      "* file4 - 07/wsj_0778\n",
      "* file5 - 21/wsj_2172\n",
      "\n",
      "(More information is available in a\n",
      "[compressed file](ftp://ftp.ldc.upenn.edu/pub/ldc/data_samples/pennTB_tipster_wsj_map.tar.gz)\n",
      "via ftp, which provides the relationship between the 2,499 PTB filenames and the corresponding WSJ DOCNO strings in TIPSTER.)\n",
      "\n",
      "### <docno>.rst/\n",
      "\n",
      "A directory with three files:  \n",
      "\n",
      "* **`<docno>.lisp.name`** - discourse structure created by a human judge for a text.\n",
      "* **`<docno>.step.name`** - list of all human actions taken  \n",
      "  during the creation of the discourse structure\n",
      "* **`##`** -- a file with an integer as its name - temp file;  \n",
      "  contains last human action during creation of the discourse structure\n",
      "\t\n",
      "All annotations were produced using a discourse annotation tool that can be downloaded from http://www.isi.edu/~marcu/discourse.\n",
      "\n",
      "The files in the .rst directories are **provided only** to enable interested users **to visualize and print in a convenient format** the discourse annotations in the corpus.\n",
      "\n",
      "* **`<docno>.dis``** - contains the manually annotated discourse structure  \n",
      "  of the file **`<docno>`**  \n",
      "  The .dis files were generated automatically from the **`.step`** and **`.lisp`**  \n",
      "  files using a mapping program.  \n",
      "  More information about this program is available at http://www.isi.edu/~marcu/discourse.\n",
      "\n",
      "**IMPORTANT NOTE**: The **.lisp files may contain errors** introduced by the discourse annotation tool. Please **use the .lisp and .step files only for visualizing the trees**.  \n",
      "**Use the .dis files for training/testing purposes** (the mapping program that produced the .dis file was written so as to eliminate the errors introduced by the annotation tool).\n",
      "\n",
      "* **`<docno>.edus`** - edus (elementary discourse units) listed line by line.\n",
      "\n",
      "## RSTtrees-WSJ-double-1.0\n",
      "This directory contains the same types of files as the subdirectory RSTtrees-WSJ-main-1.0, for 53 documents which were reviewed by a second analyst. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "\n",
      "import nltk\n",
      "\n",
      "RSTDT_MAIN_ROOT = os.path.expanduser('~/corpora/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0')\n",
      "RSTDT_DOUBLE_ROOT = os.path.expanduser('~/corpora/rst_discourse_treebank/data/RSTtrees-WSJ-double-1.0')\n",
      "RSTDT_TOKENIZED_ROOT = os.path.expanduser('~/repos/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0-tokenized')\n",
      "\n",
      "RSTDT_TEST_FILE = os.path.join(RSTDT_MAIN_ROOT, 'TEST', 'wsj_1306.out.dis')\n",
      "RSTDT_TOKENIZED_TEST_FILE = os.path.join(RSTDT_TOKENIZED_ROOT, 'TEST', 'wsj_1306.out.dis')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Find unparsable files\n",
      "\n",
      "* only 3 files that nltk's Bracket parser can't handle at all"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FILES_UNPARSABLE_WITH_NLTK = set([\n",
      "    '/home/arne/corpora/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0/TRAINING/wsj_1107.out.dis',\n",
      "    '/home/arne/corpora/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0/TRAINING/wsj_2353.out.dis',\n",
      "    '/home/arne/corpora/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0/TRAINING/wsj_2367.out.dis'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_nodelabel(node):\n",
      "    \"\"\"returns the node label of an nltk Tree or one of its subtrees\"\"\"\n",
      "    if isinstance(node, nltk.tree.Tree):\n",
      "        return node.label()\n",
      "    elif isinstance(node, unicode):\n",
      "        return node.encode('utf-8')\n",
      "    else:\n",
      "        raise ValueError(\"Unexpected node type: {}, {}\".format(type(node), node))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus.reader import BracketParseCorpusReader\n",
      "\n",
      "def parse_rstfile_nltk(rst_filepath):\n",
      "    \"\"\"parse a *.dis RST file into an nltk.tree.Tree\"\"\"\n",
      "    rst_path, rst_filename = os.path.split(rst_filepath)\n",
      "    parsed_doc = BracketParseCorpusReader(rst_path, [rst_filename])\n",
      "    parsed_sents_iter = parsed_doc.parsed_sents()\n",
      "    return parsed_sents_iter[0] # there's only one tree in a *.dis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "def nested_tree_count(tree, result_dict=None):\n",
      "    if not result_dict:\n",
      "        result_dict = defaultdict(lambda : defaultdict(int))\n",
      "    for i, subtree in enumerate(tree):\n",
      "        if isinstance(subtree, nltk.tree.Tree) and subtree.label() in ('Nucleus', 'Satellite'):\n",
      "            rhs = tuple([get_nodelabel(st) for st in subtree])\n",
      "            result_dict[get_nodelabel(subtree)][rhs] += 1\n",
      "            if rhs[0] == u'leaf' and len(rhs) != 3: # (leaf, rel2par, text)\n",
      "                raise ValueError('Badly escaped s-expression\\n{}\\n'.format(subtree))\n",
      "            nested_tree_count(subtree, result_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Files with bad escaping\n",
      "\n",
      "* 22 badly escaped files\n",
      "\n",
      "## \"(\" and \")\" aren't escaped in text field!\n",
      "\n",
      "* /home/arne/corpora/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0/TRAINING/wsj_0612.out.dis\n",
      "\n",
      "```\n",
      "  ( Satellite (span 22 28) (rel2par elaboration-set-member-e)\n",
      "    ( Nucleus (span 22 23) (rel2par span)\n",
      "      ( Nucleus (leaf 22) (rel2par span) (text _!Canadian Imperial Bank of Commerce_!) )\n",
      "      ( Satellite (leaf 23) (rel2par elaboration-additional) (text _!(Canada) --_!) )\n",
      "    )\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BADLY_ESCAPED_FILES = set()\n",
      "\n",
      "for folder in ('TEST', 'TRAINING'):\n",
      "    for rst_fpath in glob.glob(os.path.join(RSTDT_MAIN_ROOT, folder, '*.dis')):\n",
      "        if rst_fpath not in FILES_UNPARSABLE_WITH_NLTK:\n",
      "            rst_tree = parse_rstfile_nltk(rst_fpath)\n",
      "            try:\n",
      "                nested_tree_count(rst_tree)\n",
      "            except ValueError as e:\n",
      "                BADLY_ESCAPED_FILES.add(rst_fpath)\n",
      "\n",
      "len(BADLY_ESCAPED_FILES) # 22 files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "22"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Files unparsable with sexpdata (due to bad bracketing)\n",
      "\n",
      "* 113 files that aren't valid s-expressions (nltk parses them, as it is very forgiving)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import traceback\n",
      "import sexpdata\n",
      "\n",
      "def parse_rstfile_sexpdata(rst_filepath):\n",
      "    with open(rst_filepath) as rstfile:\n",
      "        try:\n",
      "            return sexpdata.load(rstfile)\n",
      "        except sexpdata.ExpectClosingBracket as e:\n",
      "            raise ValueError(u\"{}\\n{}\\n\\n\".format(rst_fpath, e))\n",
      "        except sexpdata.ExpectNothing as e:\n",
      "            error_msg = e.args[0][:100] # complete msg contains whole document\n",
      "            raise ValueError(u\"{}\\n{}...\\n\\n\".format(rst_fpath, e.args[0][:100]))\n",
      "        except AssertionError as e:\n",
      "            raise ValueError(u\"{}\\n{}\\n\\n\".format(rst_fpath, traceback.format_exc()))\n",
      "        except AttributeError as e:\n",
      "            raise ValueError(u\"{}\\n{}\\n\\n\".format(rst_fpath, traceback.format_exc()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "FILES_UNPARSABLE_WITH_SEXPDATA = set()\n",
      "for folder in ('TEST', 'TRAINING'):\n",
      "    for rst_fpath in glob.glob(os.path.join(RSTDT_MAIN_ROOT, folder, '*.dis')):\n",
      "        try:\n",
      "            parse_rstfile_sexpdata(rst_fpath)\n",
      "        except ValueError as e:\n",
      "            FILES_UNPARSABLE_WITH_SEXPDATA.add(rst_fpath)\n",
      "\n",
      "len(FILES_UNPARSABLE_WITH_SEXPDATA) # 113 unparsable files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "113"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# set of all 'unparsable' files (before tokenization and text escaping)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ALL_UNPARSABLE_FILES = FILES_UNPARSABLE_WITH_NLTK.union(FILES_UNPARSABLE_WITH_SEXPDATA).union(BADLY_ESCAPED_FILES)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(ALL_UNPARSABLE_FILES)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "124"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# try parsing files into graphs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Summary of RST tree rules\n",
      "\n",
      "* Root --> span (N+ | N S | S N)\n",
      "* Nucleus --> leaf rel2par text (N | S | re.compile('.*_!') )?\n",
      "* Nucleus --> span rel2par (N+ | N S | S N | S N S)\n",
      "* Satellite --> leaf rel2par text (N | re.compile('.*_!') )?\n",
      "* Satellite --> span rel2par (N+ | N S | S | S N | S N S)\n",
      "* rel2par --> any RST relation string"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sexp_tree = parse_rstfile_sexpdata(RSTDT_TEST_FILE)\n",
      "# a list that contains Symbol instances (and lists of Symbol instances and integers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root = sexp_tree[0]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sexp_tree[1]\n",
      "print sexp_tree[1][0]\n",
      "print sexp_tree[1][0].value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Symbol('span'), 1, 47]\n",
        "Symbol('span')\n",
        "span\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nuc_tree = sexp_tree[2]\n",
      "print nuc_tree[0]\n",
      "print nuc_tree[1]\n",
      "print nuc_tree[1][0].value()\n",
      "print nuc_tree[2]\n",
      "print nuc_tree[2][1].value()\n",
      "print nuc_tree[3][4][3][3][3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Symbol('Nucleus')\n",
        "[Symbol('span'), 1, 20]\n",
        "span\n",
        "[Symbol('rel2par'), Symbol('span')]\n",
        "span\n",
        "[Symbol('text'), Symbol('_!U.S.'), Symbol('Memories'), Symbol('is'), Symbol('seeking'), Symbol('major'), Symbol('investors'), Symbol('to'), Symbol('back'), Symbol('its'), Symbol('attempt_!')]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# SEXPDATA fail:  ' must be escaped\n",
      "\n",
      "```python\n",
      ">>> sexpdata.loads(\"(text this won't hurt)\")\n",
      ">>> [Symbol('text'), Symbol('this'), Symbol('won'), Quoted(True), Symbol('hurt')]\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Epic fail: RST-DT files contain superflous ``//TT_ERR`` strings\n",
      "    \n",
      "* I fixed the files in the ``RSTtrees-WSJ-main-1.0-tokenized`` directory\n",
      "\n",
      "```\n",
      "arne@ziegelstein ~/repos/rst_discourse_treebank $ ack-grep -cl \"//TT_ERR\"\n",
      "data/RSTtrees-WSJ-main-1.0/TRAINING/wsj_2367.out.dis:102\n",
      "data/RSTtrees-WSJ-main-1.0/TRAINING/wsj_2353.out.dis:53\n",
      "data/RSTtrees-WSJ-main-1.0-tokenized/TRAINING/wsj_2367.out.dis:102\n",
      "data/RSTtrees-WSJ-main-1.0-tokenized/TRAINING/wsj_2353.out.dis:53\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discoursegraphs as dg\n",
      "from collections import Counter\n",
      "\n",
      "class RSTLispDocumentGraph(dg.DiscourseDocumentGraph):\n",
      "    \"\"\"\n",
      "    A directed graph with multiple edges (based on a networkx\n",
      "    MultiDiGraph) that represents the rhetorical structure of a\n",
      "    document.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    name : str\n",
      "        name, ID of the document or file name of the input file\n",
      "    ns : str\n",
      "        the namespace of the document (default: rst)\n",
      "    root : str\n",
      "        name of the document root node ID\n",
      "    tokens : list of str\n",
      "        sorted list of all token node IDs contained in this document graph\n",
      "    \"\"\"\n",
      "    def __init__(self, dis_filepath, name=None, namespace='rst',\n",
      "                 tokenize=True, precedence=False):\n",
      "        \"\"\"\n",
      "        Creates an RSTLispDocumentGraph from a Rhetorical Structure *.dis file and adds metadata\n",
      "        to it.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        dis_filepath : str\n",
      "            absolute or relative path to the Rhetorical Structure *.dis file to be\n",
      "            parsed.\n",
      "        name : str or None\n",
      "            the name or ID of the graph to be generated. If no name is\n",
      "            given, the basename of the input file is used.\n",
      "        namespace : str\n",
      "            the namespace of the document (default: rst)\n",
      "        precedence : bool\n",
      "            If True, add precedence relation edges\n",
      "            (root precedes token1, which precedes token2 etc.)\n",
      "        \"\"\"\n",
      "        # super calls __init__() of base class DiscourseDocumentGraph\n",
      "        super(RSTLispDocumentGraph, self).__init__()\n",
      "\n",
      "        self.name = name if name else os.path.basename(dis_filepath)\n",
      "        self.ns = namespace\n",
      "        self.root = 0\n",
      "        self.add_node(self.root, layers={self.ns}, label=self.ns+':root_node')\n",
      "        if 'discoursegraph:root_node' in self:\n",
      "            self.remove_node('discoursegraph:root_node')\n",
      "        \n",
      "        self.tokens = []\n",
      "        self.rst_tree = parse_rstfile_sexpdata(dis_filepath)\n",
      "        self.parse_rst_tree(self.rst_tree)\n",
      "        \n",
      "    def parse_rst_tree(self, rst_tree, indent=0):\n",
      "        tree_type = self.get_tree_type(rst_tree)\n",
      "        assert tree_type in ('Root', 'Nucleus', 'Satellite')\n",
      "        if tree_type == 'Root':\n",
      "            span, children = rst_tree[1], rst_tree[2:]\n",
      "            for child in children:\n",
      "                self.parse_rst_tree(child, indent=indent+1)\n",
      "\n",
      "        else: # tree_type in ('Nucleus', 'Satellite')\n",
      "            node_id = self.get_node_id(rst_tree)\n",
      "            node_type = self.get_node_type(rst_tree)\n",
      "            relation_type = self.get_relation_type(rst_tree)\n",
      "            if node_type == 'leaf':\n",
      "                edu_text = self.get_edu_text(rst_tree[3])\n",
      "                self.add_node(node_id, node_attrs={self.ns+':text': edu_text})\n",
      "            else: # node_type == 'span'\n",
      "                children = rst_tree[3:]\n",
      "                for child in children:\n",
      "                    self.parse_rst_tree(child, indent=indent+1)\n",
      "\n",
      "#         raise NotImplementedError\n",
      "\n",
      "\n",
      "    def get_edu_text(self, text_subtree):\n",
      "        assert text_subtree[0].value() == 'text'\n",
      "        return u' '.join(word.value().decode('utf-8')\n",
      "                         if isinstance(word, sexpdata.Symbol) else word.decode('utf-8')\n",
      "                         for word in text_subtree[1:])\n",
      "        \n",
      "    def get_tree_type(self, tree):\n",
      "        \"\"\"returns the type of the (sub)tree: Root, Nucleus or Satellite\"\"\"\n",
      "        tree_type = tree[0].value()\n",
      "        return tree_type\n",
      "\n",
      "    def get_node_type(self, tree):\n",
      "        \"\"\"returns the node type (leaf or span) of a subtree (i.e. Nucleus or Satellite)\"\"\"\n",
      "        node_type = tree[1][0].value()\n",
      "        assert node_type in ('leaf', 'span')\n",
      "        return node_type\n",
      "\n",
      "    def get_relation_type(self, tree):\n",
      "        \"\"\"returns the RST relation type attached to the parent node of an RST relation\"\"\"\n",
      "        return tree[2][1].value()\n",
      "\n",
      "    def get_node_id(self, span_or_leaf):\n",
      "        node_type = self.get_node_type(span_or_leaf)\n",
      "        if node_type == 'leaf':\n",
      "            leaf_id = span_or_leaf[1][0]\n",
      "            return '{}:{}'.format(self.ns, leaf_id)\n",
      "        else: # node_type == 'span'\n",
      "            span_start = span_or_leaf[1][0]\n",
      "            span_end = span_or_leaf[1][1]\n",
      "            return '{}:span:{}-{}'.format(self.ns, span_start, span_end)\n",
      "        \n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RSTDT_TOKENIZED_ROOT = os.path.expanduser('~/repos/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0-tokenized')\n",
      "\n",
      "import traceback\n",
      "\n",
      "for folder in ('TEST', 'TRAINING'):\n",
      "    for rst_fpath in glob.glob(os.path.join(RSTDT_TOKENIZED_ROOT, folder, '*.dis')):\n",
      "            RSTLispDocumentGraph(rst_fpath)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rdg = RSTLispDocumentGraph(RSTDT_TOKENIZED_TEST_FILE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext gvmagic\n",
      "%dotstr dg.print_dot(rdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The gvmagic extension is already loaded. To reload it, use:\n",
        "  %reload_ext gvmagic\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "svg": [
        "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
        "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
        " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
        "<!-- Generated by graphviz version 2.36.0 (20140111.2315)\n",
        " -->\n",
        "<!-- Title: wsj_1306.out.dis Pages: 1 -->\n",
        "<svg width=\"283pt\" height=\"44pt\"\n",
        " viewBox=\"0.00 0.00 283.00 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
        "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
        "<title>wsj_1306.out.dis</title>\n",
        "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-40 279,-40 279,4 -4,4\"/>\n",
        "<!-- 0 -->\n",
        "<g id=\"node1\" class=\"node\"><title>0</title>\n",
        "<ellipse fill=\"none\" stroke=\"black\" cx=\"57\" cy=\"-18\" rx=\"57.2688\" ry=\"18\"/>\n",
        "<text text-anchor=\"middle\" x=\"57\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">rst:root_node</text>\n",
        "</g>\n",
        "<!-- rst:Symbol(&#39;leaf&#39;) -->\n",
        "<g id=\"node2\" class=\"node\"><title>rst:Symbol(&#39;leaf&#39;)</title>\n",
        "<ellipse fill=\"none\" stroke=\"black\" cx=\"204\" cy=\"-18\" rx=\"71.2405\" ry=\"18\"/>\n",
        "<text text-anchor=\"middle\" x=\"204\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">rst:Symbol(&#39;leaf&#39;)</text>\n",
        "</g>\n",
        "</g>\n",
        "</svg>\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.path.basename(RSTDT_TEST_FILE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PTB_TEST_FILE = os.path.expanduser('~/corpora/pennTreebank/parsed/mrg/wsj/13/wsj_1306.mrg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Map document offsets to result string offsets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discoursegraphs as dg\n",
      "import match\n",
      "\n",
      "pdg = dg.read_ptb(PTB_TEST_FILE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sent0_root = pdg.sentences[0]\n",
      "ptb_1306_tokens = list(pdg.get_tokens(token_strings_only=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tokenize all EDUs with OpenNLP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "# a string enclosed in '_!', possibly with '<P>' before the closing '_!' \n",
      "RST_DIS_TEXT_REGEX = re.compile(\"_!(.*?)(\\<P\\>)?_!\", re.DOTALL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Epic Fail: we can't use nltk's Bracket parser, as it parses (span 1 5) as (span 1)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rst_tree = parse_rstfile_nltk(RSTDT_TEST_FILE)\n",
      "span_tree = rst_tree[0]\n",
      "print span_tree, span_tree.productions(), span_tree.leaves()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print open(RSTDT_TEST_FILE).read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}