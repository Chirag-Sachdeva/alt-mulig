{
 "metadata": {
  "name": "",
  "signature": "sha256:9be11cbdba84ca92a669b89857340db64bc6385ba198129924ff579b569a751e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Task: add missing sentence-level annotations to Exmaralda files"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "AP told me that 20 of the Exmaralda-annotated MAZ176 files don't have a `tiger:sentence` tier.\n",
      "\n",
      "```\n",
      "$ for i in *.exb ; do grep -cH \"category=\\\"sentence\\\"\" $i ; done | grep \"0$\"\n",
      "maz-00001.exb:0\n",
      "maz-00002.exb:0\n",
      "maz-1423.exb:0\n",
      "maz-1453.exb:0\n",
      "maz-1679.exb:0\n",
      "maz-1757.exb:0\n",
      "maz-1818.exb:0\n",
      "maz-2316.exb:0\n",
      "maz-2609.exb:0\n",
      "maz-2611.exb:0\n",
      "maz-2669.exb:0\n",
      "maz-3073.exb:0\n",
      "maz-3080.exb:0\n",
      "maz-3110.exb:0\n",
      "maz-3277.exb:0\n",
      "maz-3367.exb:0\n",
      "maz-3377.exb:0\n",
      "maz-3415.exb:0\n",
      "maz-3547.exb:0\n",
      "maz-4031.exb:0\n",
      "```\n",
      "\n",
      "The annotations mentioned are present in the Exmaralda files I gave to the annotator:\n",
      "\n",
      "```\n",
      "$ /tmp/pcc176_tiger2exmaralda $ ack-grep -c \"category=\\\"sentence\\\"\" | cut -d : -f 2 | uniq \n",
      "1\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import glob\n",
      "from operator import itemgetter, attrgetter\n",
      "\n",
      "from lxml import etree\n",
      "from discoursegraphs import DiscourseDocumentGraph, EdgeTypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BROKEN_EXMARALDA_DIR = os.path.expanduser('~/repos/pcc-annis-merged/maz176/information-structure/')\n",
      "exmaralda_files = glob.glob(os.path.join(BROKEN_EXMARALDA_DIR, '*.exb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_token_ids(exmaralda_etree):\n",
      "    \"\"\"\n",
      "    returns a list of all token IDs occuring the the given exmaralda file,\n",
      "    sorted by their time stamp in ascending order.\n",
      "    \"\"\"\n",
      "    def tok2time(token_element):\n",
      "        '''\n",
      "        extracts the time (float) of a <tli> element\n",
      "        (i.e. the absolute position of a token in the document)\n",
      "        '''\n",
      "        return float(token_element.attrib['time'])\n",
      "\n",
      "    timeline = exmaralda_etree.find('//common-timeline')\n",
      "    return (tok.attrib['id'] \n",
      "            for tok in sorted((tli for tli in timeline.iterchildren()),\n",
      "                              key=tok2time))\n",
      "\n",
      "def tokenid2index(token_id):\n",
      "    \"\"\"converts a token ID (e.g. 'T0') to its index (i.e. 0)\"\"\"\n",
      "    return int(token_id[1:])\n",
      "\n",
      "def indexdelta(stop_id, start_id):\n",
      "    return tokenid2index(stop_id) - tokenid2index(start_id)\n",
      "\n",
      "def gen_token_range(start_id, stop_id):\n",
      "    \"\"\"\n",
      "    halboffenes Intervall [start, stop)\n",
      "    \n",
      "    >>> gen_token_range('T0', 'T1')\n",
      "    ['T0']\n",
      "    \n",
      "    >>> gen_token_range('T1', 'T5')\n",
      "    ['T1', 'T2', 'T3', 'T4']\n",
      "    \"\"\"\n",
      "    index_range = range(tokenid2index(start_id), tokenid2index(stop_id))\n",
      "    return [\"T{}\".format(index) for index in index_range]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ExmaraldaDocumentGraph(DiscourseDocumentGraph):\n",
      "    def __init__(self, exmaralda_file, name=None, namespace='exmaralda',\n",
      "                 token_tier='tok', ignored_tier_categories=[]):\n",
      "        # super calls __init__() of base class DiscourseDocumentGraph\n",
      "        super(ExmaraldaDocumentGraph, self).__init__()\n",
      "        self.name = name if name else os.path.basename(exmaralda_file)\n",
      "        self.ns = namespace\n",
      "        self.root = self.ns+':root_node'\n",
      "        \n",
      "        tree = etree.parse(exmaralda_file)\n",
      "        self.tokens = []\n",
      "        \n",
      "        self.__add_tokenization(tree)\n",
      "        \n",
      "        for tier in tree.iter('tier'):\n",
      "            if tier.attrib['category'] not in ignored_tier_categories:\n",
      "                self.__add_tier(tier, token_tier_name=token_tier)\n",
      "    \n",
      "    def __add_tokenization(self, tree):\n",
      "        \"\"\"adds a node for each token ID in the document\"\"\"\n",
      "        for token_id in get_token_ids(tree):\n",
      "            self.add_node(token_id, layers={self.ns})\n",
      "            self.tokens.append(token_id)\n",
      "    \n",
      "    def __add_tier(self, tier, token_tier_name):\n",
      "        tier_id = tier.attrib['id']\n",
      "        tier_category = tier.attrib['category']\n",
      "        if tier_category == token_tier_name: # add token annotations\n",
      "            for event in tier.iter('event'):\n",
      "                assert indexdelta(event.attrib['end'], event.attrib['start']) == 1, \\\n",
      "                    \"Events in the token tier must not span more than one token.\"\n",
      "                token_id = event.attrib['start']\n",
      "                self.node[token_id][self.ns+':token'] = event.text\n",
      "        else: # add span annotations to span tiers\n",
      "            self.add_node( # add a node for each tier\n",
      "                tier_id, layers={self.ns, self.ns+':tier'},\n",
      "                attr_dict={self.ns+':category': tier.attrib['category'],\n",
      "                           self.ns+':type': tier.attrib['type'],\n",
      "                           self.ns+':display-name': tier.attrib['display-name']})\n",
      "            self.add_edge(self.root, tier_id, edge_type=EdgeTypes.dominance_relation)\n",
      "            \n",
      "            for i, event in enumerate(tier.iter('event')):\n",
      "                span_id = '{}_{}'.format(tier_id, i)\n",
      "                span_tokens = gen_token_range(event.attrib['start'], event.attrib['end'])\n",
      "                annotation = event.text if event.text else ''\n",
      "                self.add_node(\n",
      "                    span_id, layers={self.ns, self.ns+':span'},\n",
      "                    attr_dict={self.ns+':annotation': annotation,\n",
      "                               'label': annotation})\n",
      "                self.add_edge(tier_id, span_id, edge_type=EdgeTypes.dominance_relation)\n",
      "                \n",
      "                for token_id in span_tokens:\n",
      "                    self.add_edge(span_id, token_id,\n",
      "                                  edge_type=EdgeTypes.spanning_relation)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exb_1423 = '/home/arne/repos/pcc-annis-merged/maz176/information-structure/maz-1423.exb'\n",
      "edg = ExmaraldaDocumentGraph(exb_1423)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from discoursegraphs import info, select_nodes_by_layer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tier_id in select_nodes_by_layer(edg, 'exmaralda:tier'):\n",
      "    print edg.node[tier_id]['exmaralda:category']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "syntax\n",
        "markable\n",
        "SEGMENT\n",
        "SEGMENT-1\n",
        "THETICITY\n",
        "THETICITY-1\n",
        "TOPIC\n",
        "syntax\n",
        "syntax\n",
        "syntax\n",
        "markable\n",
        "pos\n",
        "syntax\n",
        "syntax\n",
        "chain\n",
        "chain\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from discoursegraphs.readwrite import MMAXDocumentGraph\n",
      "from discoursegraphs.readwrite.exmaralda import write_exb\n",
      "\n",
      "MMAX_DIR = os.path.expanduser('/home/arne/repos/pcc-annis-merged/maz176/coreference/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "get all tier categories from the corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "```python\n",
      "from collections import Counter\n",
      "\n",
      "tier_categories = Counter()\n",
      "\n",
      "for exmaralda_file in exmaralda_files:\n",
      "    edg = ExmaraldaDocumentGraph(exmaralda_file)\n",
      "    for tier_id in select_nodes_by_layer(edg, 'exmaralda:tier'):\n",
      "        tier_categories[edg.node[tier_id]['exmaralda:category']] += 1\n",
      "\n",
      ">>> tier_categories.most_common()\n",
      "[('syntax', 1077),\n",
      " ('sentence', 312),\n",
      " ('SEGMENT', 183),\n",
      " ('pos', 176),\n",
      " ('SEGMENT-1', 166),\n",
      " ('SEGMENT-2', 113),\n",
      " ('markable', 59),\n",
      " ('chain', 42),\n",
      " ('comment', 37),\n",
      " ('THETICITY', 20),\n",
      " ('TOPIC', 20),\n",
      " ('THETICITY-1', 19),\n",
      " ('SEGMENT-3', 19),\n",
      " ('secedge', 12),\n",
      " ('THETICITY-2', 9),\n",
      " ('THETICITY-3', 2),\n",
      " ('SEGMENT-4', 1),\n",
      " ('SENTENCE-1', 1),\n",
      " ('SEGMENTT-1', 1),\n",
      " ('THETIC-1', 1),\n",
      " ('THETIC-2', 1),\n",
      " ('SEGMENT4', 1),\n",
      " ('SEGMENNT-1', 1),\n",
      " ('v', 1)]\n",
      " ```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# merged_graphs = []\n",
      "# for exmaralda_file in exmaralda_files:\n",
      "#     doc_id = os.path.basename(exmaralda_file).split('.')[0]\n",
      "#     edg = ExmaraldaDocumentGraph(exmaralda_file,\n",
      "#                                  ignored_tier_categories=['syntax', 'pos', 'sentence', 'chain', 'markable', 'secedge'])\n",
      "#     mdg = MMAXDocumentGraph(os.path.join(MMAX_DIR, doc_id+'.mmax'))\n",
      "#     write_exb(mdg, '/tmp/{}_mmax.exb'.format(doc_id))\n",
      "#     mdg.merge_graphs(edg)\n",
      "#     write_exb(mdg, '/tmp/{}_mmax+exb.exb'.format(doc_id))\n",
      "    \n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Why are `sentence` tiers empty?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mmax_files = glob.glob(os.path.join(MMAX_DIR, '*.mmax'))\n",
      "for mmax_file in mmax_files:\n",
      "    mdg = MMAXDocumentGraph(mmax_file)\n",
      "    print len(mdg.sentences),"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15 12 12 11 9 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 12 11 33 16 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9 16 9 9 13 16 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15 11 11 19 13 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 11 16 10 16 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7 12 12 9 21 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 12 14 13 10 11 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 10 12 13 12 10 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 14 14 14 10 15 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 14 21 13 15 14 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 11 12 13 12 14 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 14 14 12 11 13 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 11 12 11 11 17 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 14 19 12 14 15 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 12 12 9 11 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16 12 14 13 18 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 14 11 12 11 13 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 15 15 10 16 15 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8 10 11 10 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14 10 12 17 7 10 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "17 16 15 11 17 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 11 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 12 12 13 9 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 11 12 9 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 19 18 15 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 18 13 14 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14 11 11 11 10 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 12 11 12 8 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 12 10 14 14 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "14 15 10 10 21 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 11 11 7 14 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12 19 14 16 12 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "9 10 10\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdg = MMAXDocumentGraph(os.path.join(MMAX_DIR, 'maz-1423.mmax'))\n",
      "write_exb(mdg, '/tmp/foo.exb')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "sentence markables are annotated, but mdg.out_edges(sent_mark) returns an empty list!"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}