{
 "metadata": {
  "name": "",
  "signature": "sha256:4dd0cdad5e5a1b6215f9e157c5c046fea526a328f1c545a1d6155ec53921cbe3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "from stanford_corenlp_pywrapper import sockwrap\n",
      "\n",
      "CORENLP_PYWRAPPER_DIR = os.path.expanduser('~/repos/stanford_corenlp_pywrapper')\n",
      "jars = (\"stanford-corenlp-full-2014-08-27/stanford-corenlp-3.4.1.jar\",\n",
      "        \"stanford-corenlp-full-2014-08-27/stanford-corenlp-3.4.1-models.jar\")\n",
      "\n",
      "p=sockwrap.SockWrap(\"pos\",\n",
      "                    corenlp_jars=[os.path.join(CORENLP_PYWRAPPER_DIR, jar) for jar in jars])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:StanfordSocketWrap:Starting pipe subprocess, and waiting for signal it's ready, with command:  exec java -Xmx4g -cp '/usr/local/lib/python2.7/dist-packages/stanford_corenlp_pywrapper/lib/piperunner.jar:/usr/local/lib/python2.7/dist-packages/stanford_corenlp_pywrapper/lib/guava-13.0.1.jar:/usr/local/lib/python2.7/dist-packages/stanford_corenlp_pywrapper/lib/jackson-all-1.9.11.jar:/home/arne/repos/stanford_corenlp_pywrapper/stanford-corenlp-full-2014-08-27/stanford-corenlp-3.4.1.jar:/home/arne/repos/stanford_corenlp_pywrapper/stanford-corenlp-full-2014-08-27/stanford-corenlp-3.4.1-models.jar'     corenlp.PipeCommandRunner --server 12340  --mode pos\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:StanfordSocketWrap:Successful ping. The server has started.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:StanfordSocketWrap:Subprocess is ready.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import discoursegraphs as dg\n",
      "\n",
      "# a string enclosed in '_!', possibly with '<P>' before the closing '_!' \n",
      "RST_DIS_TEXT_REGEX = re.compile(\"_!(.*?)(\\<P\\>)?_!\", re.DOTALL)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corenlp_result = p.parse_doc(\"\"\"that its money would be better spent \"in areas such as research\" and development.\"\"\")\n",
      "\n",
      "print ' '.join(tok for sent in corenlp_result['sentences'] for tok in sent['tokens'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "that its money would be better spent `` in areas such as research '' and development .\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import glob\n",
      "import os\n",
      "import dataset\n",
      "import codecs\n",
      "\n",
      "RSTDT_MAIN_ROOT = os.path.expanduser('~/repos/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0')\n",
      "RSTDT_TOKENIZED_ROOT = os.path.expanduser('~/repos/rst_discourse_treebank/data/RSTtrees-WSJ-main-1.0-tokenized')\n",
      "\n",
      "RSTDT_TEST_FILE = os.path.join(RSTDT_MAIN_ROOT, 'TEST', 'wsj_1306.out.dis')\n",
      "\n",
      "def tokenize_rst_file(rst_input_path, rst_output_path):\n",
      "#     edus = {}\n",
      "    with open(rst_input_path, 'r') as rstfile, codecs.open(rst_output_path, 'w', encoding='utf-8') as outfile:\n",
      "        rstfile_str = rstfile.read()\n",
      "        input_file_onset = 0\n",
      "        edu_matches = RST_DIS_TEXT_REGEX.finditer(rstfile_str)\n",
      "\n",
      "        for edu in edu_matches:\n",
      "            doc_onset = edu.start()\n",
      "            doc_offset = edu.end()\n",
      "            doc_untokenized_str = edu.groups()[0]\n",
      "            corenlp_result = p.parse_doc(doc_untokenized_str)\n",
      "            corenlp_tokenized_str = u' '.join(tok for sent in corenlp_result['sentences'] for tok in sent['tokens'])\n",
      "            outfile.write(rstfile_str[input_file_onset:doc_onset])\n",
      "            outfile.write(u'\"{}\"'.format(corenlp_tokenized_str))\n",
      "            input_file_onset = doc_offset\n",
      "        outfile.write(rstfile_str[input_file_onset:])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# with open(RSTDT_TEST_FILE, 'r') as f:\n",
      "#     print f.read()[325]\n",
      "\n",
      "tokenize_rst_file(RSTDT_TEST_FILE, '/tmp/1306.dis')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "for folder in ('TEST', 'TRAINING'):\n",
      "    for rst_fpath in glob.glob(os.path.join(RSTDT_MAIN_ROOT, folder, '*.dis')):\n",
      "        out_fpath = os.path.join(RSTDT_TOKENIZED_ROOT, folder, os.path.basename(rst_fpath))\n",
      "        out_dir, _fname = os.path.split(out_fpath)\n",
      "        dg.util.create_dir(out_dir)\n",
      "        tokenize_rst_file(rst_fpath, out_fpath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 6.13 s, sys: 4.94 s, total: 11.1 s\n",
        "Wall time: 23.7 s\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}