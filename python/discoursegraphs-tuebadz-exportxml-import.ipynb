{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ongoing implementation of ExportXML importer (discoursegraphs branch: exportxml)\n",
    "\n",
    "* initially, I was working on Tueba/D-Z 5.0, but now I have version 8.0 available\n",
    "* the whole corpus is available as a single XML file, which would result in a graph  \n",
    "  that is way to large for networkx (ca. 1.7 million edges)\n",
    "  \n",
    "## Tueba-D/Z 5.0\n",
    "\n",
    "* I assumed that the corpus could not be split into documents and therefore wrote  \n",
    "  a parser using igraph instead of networkx\n",
    "* it turns out that each sentence has a ``origin`` attribute, e.g. ``T990507.2``,  \n",
    "  which translates into (collection ID: T990507, document id: 2)\n",
    "* all documents within a collection (NB: I will use those terms, Tueba doesn't)  \n",
    "  have consequtively numbered token node IDs, i.e. if document 1 contains sentences  \n",
    "  1 to 12, document 2 might contain sentences 13 to 43\n",
    "  \n",
    "## Tueba-D/Z 8.0\n",
    "\n",
    "* ``tuebadz-8.0-mit-NE+Anaphern+Diskurs.exml.xml`` contains bad XML\n",
    "\n",
    "```python\n",
    "XMLSyntaxError: ID text_145 already defined, line 4663422, column 20\n",
    "```\n",
    "\n",
    "* two text IDs occur twice: ``text_3160`` and ``text_145``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from lxml import etree, html\n",
    "import igraph as ig\n",
    "\n",
    "import discoursegraphs as dg\n",
    "\n",
    "TUEBADZ5_FILE = os.path.expanduser(\n",
    "    '~/corpora/tueba/tuebadz-5.0/data/XML/tuebadz-5.0.anaphora.export.xml')\n",
    "\n",
    "TUEBADZ8_FILE = os.path.expanduser(\n",
    "    '~/corpora/tueba/TuebaDZ8.0/tuebadz-8.0-mit-NE+Anaphern+Diskurs.exml.xml')\n",
    "\n",
    "HTML_PARSER = html.HTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExportXML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "texts = Counter()\n",
    "\n",
    "# recover: try hard to parse through broken input\n",
    "context = etree.iterparse(TUEBADZ8_FILE, events=('end',), recover=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_ns(key, ns='http://www.w3.org/XML/1998/namespace'):\n",
    "    \"\"\"\n",
    "    adds a namespace prefix to a string, e.g. turns 'foo' into\n",
    "    '{http://www.w3.org/XML/1998/namespace}foo'\n",
    "    \"\"\"\n",
    "    return '{{{namespace}}}{key}'.format(namespace=ns, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fast_iter(context, func):\n",
    "    \"\"\"\n",
    "    memory-saving iterator for lxml's iterparse.\n",
    "    cf. http://www.ibm.com/developerworks/library/x-hiperfparse/\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    context : lxml.etree.iterparse\n",
    "        an iterparse iterator over an XML file\n",
    "    func : function\n",
    "        a function that will be called for each element of the context\n",
    "    \"\"\"\n",
    "    for event, elem in context:\n",
    "        func(elem)\n",
    "        # removes element (and references to it) from memory after processing it\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    del context\n",
    "\n",
    "def conditional_fast_iter(context, condition, func):\n",
    "    \"\"\"\n",
    "    memory-saving iterator for lxml's iterparse, which runs\n",
    "    a function on every element satisfying the given condition.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    context : lxml.etree.iterparse\n",
    "        an iterparse iterator over an XML file\n",
    "    condition : str\n",
    "        a string that represents a condition and which must\n",
    "        return True or False when evaluated with eval(condition)\n",
    "    func : function\n",
    "        a function that will be called for each element of the context\n",
    "    \"\"\"\n",
    "    for event, elem in context:\n",
    "        if eval(condition) == True:\n",
    "            yield func(elem)\n",
    "        # removes element (and references to it) from memory after processing it\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "    del context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_text(text_element):\n",
    "    text_str = 'ID: {}\\nOrigin: {}\\n\\n'.format(text_element.attrib[add_ns('id')], text_element.attrib['origin'])\n",
    "    for sentence in text_element.xpath('//sentence'):\n",
    "        sent_str = u' '.join(word.attrib['form'] for word in sentence.xpath('.//word'))\n",
    "        text_str += u'{}\\n'.format(sent_str)\n",
    "    return text_str\n",
    "\n",
    "context = etree.iterparse(TUEBADZ8_FILE, events=('end',), recover=True)\n",
    "texts = conditional_fast_iter(context, 'elem.tag == \"text\"', get_text)\n",
    "# texts = conditional_fast_iter(context, 'elem.tag == \"text\"', lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: text_0\n",
      "Origin: T990507.2\n",
      "\n",
      "\n",
      "SPD / CDU / AfB für Daewoo-Millionen\n",
      "Aber Bremerhavens AfB fordert jetzt Untersuchungsausschuß\n",
      "Die Wirtschaftsförderausschüsse haben gestern ein Finanzierungsvolumen von insgesamt 86 Millionen Mark beschlossen , mit denen das Vulkan-Gelände für die Ansiedlung des Autoimporteurs Egerland frei gemacht werden kann .\n",
      "Egerland soll die 10.000 bis 20.000 koreanischen Daewoo-Pkw , die derzeit von der Firma Mosolf in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print texts.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = etree.parse('exportxml/text0_exportxml.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree.xpath('//sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree.xpath('//node'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "675"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree.xpath('//word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 17 6 26 15 39 40 12 26 24 10 8 22 18 26 21 19 25 19 16 32 14 28 20 19 17 21 16 22 19 13 14 30 14 2\n"
     ]
    }
   ],
   "source": [
    "for sentence in tree.xpath('//sentence'):\n",
    "    print len(sentence.xpath('.//word')),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.iter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: text_0\n",
      "Origin: T990507.2\n",
      "\n",
      "s1 5\n",
      "Veruntreute die AWO Spendengeld ?\n",
      "s2 17\n",
      "Staatsanwaltschaft muß AWO-Konten prüfen / Flossen 165.000 Mark Sammelgelder für Flutopfer in ein Altenheim in Danzig ?\n",
      "s3 6\n",
      "Landesvorsitzende Ute Wedemeier : Ein Buchungsfehler\n",
      "s4 26\n",
      "Im Januar hat die Arbeiterwohlfahrt Bremen ihren langjährigen Geschäftsführer Hans Taake fristlos entlassen , nun wird auch der Vorstand der Wohlfahrtsorganisation in den Fall hineingezogen .\n",
      "s5 15\n",
      "In einer anonymen Anzeige werden der Bremer Staatsanwaltschaft Details über dubiose finanzielle Transaktionen mitgeteilt .\n",
      "s6 39\n",
      "Verantwortlich , so das Schreiben einer Mitarbeiterin der AWO , sei die Landesvorsitzende Uter Wedemeier , die sich jetzt als \" Sauberfrau \" gebe , \" wo doch alle wissen , wie eng sie mit Taake zusammenhing \" .\n",
      "s7 40\n",
      "Vorwurf Nummer 1 : 165.000 Mark aus der bundesweiten Geldsammlung für die Flutopfer in Südpolen seien über das Konto des Bremer Landesverbandes der AWO an die Caritas in Danzig geflossen , \" damit dort ein Altenheim gebaut wird \" .\n",
      "s8 12\n",
      "Das Altenheim sei \" ein Prestigeobjekt von ihr und anderen \" .\n",
      "s9 26\n",
      "In der Tat sitzt Ute Wedemeier im Kuratorium für das Altenheim , eine derartige Umleitung von Geldern habe es aber nicht gegeben , sagt sie .\n",
      "s10 24\n",
      "\" Wenn da was gebucht worden ist , dann ist das nicht in Ordnung \" - höchstens einen Buchungsfehler kann sie sich vorstellen .\n",
      "s11 10\n",
      "Volker Tegeler , stellvertretender Geschäftsführer des Landesverbandes , sagt :\n",
      "s12 8\n",
      "\" Es gibt so eine Buchung . \"\n",
      "s13 22\n",
      "In einer internen Kontrolle nach der Kündigung von Taake sei dies aufgefallen , zur Aufklärung solle ein externer Wirtschaftsprüfer beauftragt werden .\n",
      "s14 18\n",
      "Verantwortlich für die Finanzen des Landesverbandes sei aber \" durchgehend Herr Taake \" gewesen , sagt Tegeler .\n",
      "s15 26\n",
      "Aufgefallen bei der internen Prüfung ist auch Vorwurf Nummer 2 : Die AWO hat sich für Seniorenreisen nach Mallorca von Hapaq Lloyd Provisionen zahlen lassen .\n",
      "s16 21\n",
      "Die seien auf ein Konto des Landesverbandes der AWO geflossen , weil sie dort vor einer Finanzamtsprüfung sicherer gewesen seien .\n",
      "s17 19\n",
      "Tegeler bestätigt den Vorgang der Provisionszahlungen , meint allerdings , es müsse ein \" Buchungsfehler \" gewesen sein .\n",
      "s18 25\n",
      "Die ehrenamtliche Landesvorsitzende Wedemeier weiß von diesem Vorgang nichts , \" ich kontrolliere solche Sachen doch nicht , das machen die hauptamtlichen Geschäftsführer . \"\n",
      "s19 19\n",
      "Kontrolliert werden die Geschäftsführer von den gewählten Revisoren des AWO-Landesverbandes , das sind Detlev Griesche und Karin Freudenthal .\n",
      "s20 16\n",
      "Freuden-thal wollte gestern nichts dazu sagen , ob bei ihren Prüfungen ihr etwas aufgefallen sei .\n",
      "s21 32\n",
      "Da der Landesverband als Dachverband ohne hauptamtliches Personal nur einen \" ganz kleinen Haushalt \" hat ( Wedemeier ) , hätten Summen von Hapaq Lloyd oder 165.000 Mark schon auffallen müssen .\n",
      "s22 14\n",
      "Vorwurf Nummer 3 : Die Landesvorsitzende Ute Wedemeier hatte auf AWO-Kosten ein Handy .\n",
      "s23 28\n",
      "\" Hier werden Beiträge von kleinen Leuten veraast , die von ehrenamtlichen Kassierern fünf Mark weise gesammelt werden \" , schreibt die anonyme AWO-Mitarbeiterin an die Staatsanwaltschaft .\n",
      "s24 20\n",
      "Obwohl Frau Wedemeier \" vor allem Privatgespräche über das Handy \" führe , würde alles von der AWO bezahlt .\n",
      "s25 19\n",
      "Ute Wedemeier hält es für \" selbstverständlich \" , daß sie als ehrenamtliche Vorsitzende ein dienstliches Handy hat .\n",
      "s26 17\n",
      "Insbesondere wegen ihrer Aktivitäten in Riga und Danzig müsse sie erreichbar sein und auch telefonieren können .\n",
      "s27 21\n",
      "Wieviel da monatlich fällig wird , weiß sie aber nicht - \" die Rechnung geht direkt an die AWO \" .\n",
      "s28 16\n",
      "Hintergrund der gegenseitigen Vorwürfe in der Arbeiterwohlfahrt sind offenbar scharfe Konkurrenzen zwischen Bremern und Bremerhavenern .\n",
      "s29 22\n",
      "Als es in dieser Woche um die Neubesetzung des ehrenamtlichen Geschäftsführer-Postens im Landesverbandes ging , da sind diese Differenzen wieder aufgebrochen .\n",
      "s30 19\n",
      "Lothar Koring , Bremerhavener AWO-Vorsitzender , wollte seinen Bremerhavener Geschäftsführer Volker Tegeler auch im Landesverband zum Geschäftsführer machen .\n",
      "s31 13\n",
      "Koring selbst hatte früher auch gegen Ute Wedemeier für den Landesvorsitz kandidiert .\n",
      "s32 14\n",
      "Gegen Tegeler sprach allerdings , daß noch ein staatsanwaltschaftliches Ermittlungsverfahren gegen ihn läuft .\n",
      "s33 30\n",
      "Und Koring war früher einmal in schiefes Licht geraten , weil er bei einer Prüfgesellschaft im Vorstand war , die die AWO , wo er Kreisvorsitzender ist , prüfte .\n",
      "s34 14\n",
      "Seine Position bei der Prüfgesellschaft mußte er damals niederlegen , den AWO-Posten nicht .\n",
      "s35 2\n",
      "K. W.\n"
     ]
    }
   ],
   "source": [
    "for text in tree.iter('text'):\n",
    "    print 'ID: {}\\nOrigin: {}\\n'.format(text.attrib[add_ns('id')], text.attrib['origin'])\n",
    "    for sent in text.iter('sentence'):\n",
    "        print sent.attrib[add_ns('id')], len(list(sent.xpath('.//word')))\n",
    "        print ' '.join(word.attrib['form'] for word in sent.xpath('.//word'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "ID text_145 already defined, line 4663422, column 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mXMLSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m ID text_145 already defined, line 4663422, column 20\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tree = etree.parse(TUEBADZ8_FILE)\n",
    "sentence_origins = Counter()\n",
    "\n",
    "sentences_iter = tree.iterfind('sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s0 = sentences_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence origin=\"T990507.2\" comment=\"%% HEADLINE\" date=\"2008020714:44:17\" editor=\"hschulz\">\n",
      "    <node cat=\"SIMPX\" parent=\"0\" comment=\"\" func=\"--\" id=\"s_1_n_506\">\n",
      "      <node cat=\"LK\" comment=\"\" func=\"-\" id=\"s_1_n_503\">\n",
      "        <node cat=\"VXFIN\" comment=\"\" func=\"HD\" id=\"s_1_n_500\">\n",
      "          <word comment=\"\" form=\"Veruntreute\" func=\"HD\" pos=\"VVFIN\" morph=\"3sit\" id=\"s_1_n_0\"/>\n",
      "        </node>\n",
      "      </node>\n",
      "      <node cat=\"MF\" comment=\"\" func=\"-\" id=\"s_1_n_505\">\n",
      "        <node cat=\"NX\" comment=\"\" func=\"ON\" id=\"s_1_n_504\">\n",
      "          <word comment=\"\" form=\"die\" func=\"-\" pos=\"ART\" morph=\"nsf\" id=\"s_1_n_1\"/>\n",
      "          <node cat=\"EN-ADD\" comment=\"\" func=\"HD\" id=\"s_1_n_501\">\n",
      "            <word comment=\"\" form=\"AWO\" func=\"-\" pos=\"NN\" morph=\"nsf\" id=\"s_1_n_2\"/>\n",
      "          </node>\n",
      "        </node>\n",
      "        <node cat=\"NX\" comment=\"\" func=\"OA\" id=\"s_1_n_502\">\n",
      "          <word comment=\"\" form=\"Spendengeld\" func=\"HD\" pos=\"NN\" morph=\"asn\" id=\"s_1_n_3\"/>\n",
      "        </node>\n",
      "      </node>\n",
      "    </node>\n",
      "    <word parent=\"0\" comment=\"\" form=\"?\" func=\"--\" pos=\"$.\" morph=\"--\" id=\"s_1_n_4\"/>\n",
      "  </sentence>\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print etree.tostring(s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExportXML ``<element>`` counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('node', 947810),\n",
       " ('word', 794079),\n",
       " ('relation', 56273),\n",
       " ('anaphora', 56273),\n",
       " ('sentence', 45200),\n",
       " ('secedge', 4647),\n",
       " ('originDef', 2213),\n",
       " ('morphDef', 437),\n",
       " ('posDef', 56),\n",
       " ('edgeDef', 50),\n",
       " ('nodeDef', 29),\n",
       " ('editorDef', 26),\n",
       " ('secedgeDef', 7),\n",
       " ('comment', 6),\n",
       " ('posList', 1),\n",
       " ('secedgeList', 1),\n",
       " ('editorList', 1),\n",
       " ('edgeList', 1),\n",
       " ('originList', 1),\n",
       " ('format', 1),\n",
       " ('morphList', 1),\n",
       " ('nodeList', 1),\n",
       " ('export', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "element_count = Counter()\n",
    "\n",
    "for element in tree.iter():\n",
    "    element_count[element.tag] += 1\n",
    "\n",
    "element_count.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about `<relation>` and `<anaphora>`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "def count_element_positions(tree, element):\n",
    "    element_positions = defaultdict(Counter)\n",
    "\n",
    "    for elem_instance in tree.iter(element):\n",
    "        element_positions['parent'][elem_instance.getparent().tag] += 1\n",
    "        for child in elem_instance.getchildren():\n",
    "            element_positions['children'][child.tag] += 1\n",
    "    return element_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<class 'collections.Counter'>, {'parent': Counter({'anaphora': 56273})})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_element_positions(tree, 'relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<class 'collections.Counter'>, {'children': Counter({'relation': 56273}), 'parent': Counter({'node': 49713, 'word': 6560})})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_element_positions(tree, 'anaphora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<anaphora>\n",
      "              <relation type=\"coreferential\" antecedent=\"s_1_n_504\"/>\n",
      "            </anaphora>\n",
      "            \n",
      "<anaphora>\n",
      "                  <relation type=\"anaphoric\" antecedent=\"s_4_n_527\"/>\n",
      "                </anaphora>\n",
      "              \n",
      "<anaphora>\n",
      "                <relation type=\"coreferential\" antecedent=\"s_4_n_527\"/>\n",
      "              </anaphora>\n",
      "              \n"
     ]
    }
   ],
   "source": [
    "anaphora_iter = tree.iter('anaphora')\n",
    "\n",
    "for i in range(3):\n",
    "    print etree.tostring(anaphora_iter.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<anaphora>\n",
      "                  <relation type=\"anaphoric\" antecedent=\"s_4_n_527\"/>\n",
      "                </anaphora>\n",
      "              \n",
      "<anaphora>\n",
      "                    <relation type=\"anaphoric\" antecedent=\"s_19_n_518\"/>\n",
      "                  </anaphora>\n",
      "                \n",
      "<anaphora>\n",
      "                  <relation type=\"anaphoric\" antecedent=\"s_25_n_505\"/>\n",
      "                </anaphora>\n",
      "              \n"
     ]
    }
   ],
   "source": [
    "anaphora_iter = tree.iter('anaphora')\n",
    "word_anaphora = [a for a in anaphora_iter if a.getparent().tag == 'word']\n",
    "for word_ana in word_anaphora[:3]:\n",
    "    print etree.tostring(word_ana)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unusual examples\n",
    "\n",
    "### expletive\n",
    "\n",
    "```\n",
    "~/corpora/tueba/tuebadz-5.0/data/XML $ ack-grep -A 5 s_11429_n_506 tuebadz-5.0.anaphora.export.xml\n",
    "        <node cat=\"NX\" comment=\"\" func=\"ON\" id=\"s_11429_n_506\">\n",
    "          <anaphora>\n",
    "            <relation type=\"expletive\" antecedent=\"\"/>\n",
    "          </anaphora>\n",
    "          <word comment=\"\" form=\"Es\" func=\"HD\" pos=\"PPER\" morph=\"nsn3\" id=\"s_11429_n_10\"/>\n",
    "        </node>\n",
    "```\n",
    "\n",
    "### split antecedent\n",
    "\n",
    "```\n",
    "27434-          <node cat=\"MF\" comment=\"\" func=\"-\" id=\"s_382_n_511\">\n",
    "27435-            <node cat=\"NX\" comment=\"\" func=\"ON\" id=\"s_382_n_501\">\n",
    "27436-              <anaphora>\n",
    "27437:                <relation type=\"split_antecedent\" antecedent=\"s_381_n_9,s_378_n_510\"/>\n",
    "27438-              </anaphora>\n",
    "27439-              <word comment=\"\" form=\"die\" func=\"-\" pos=\"ART\" morph=\"npm\" id=\"s_382_n_1\"/>\n",
    "27440-              <word comment=\"\" form=\"Partner\" func=\"HD\" pos=\"NN\" morph=\"npm\" id=\"s_382_n_2\"/>\n",
    "27441-            </node>\n",
    "27442-            <node cat=\"ADVX\" comment=\"\" func=\"OADVP\" id=\"s_382_n_502\">\n",
    "27443-              <word comment=\"\" form=\"miteinander\" func=\"HD\" pos=\"ADV\" morph=\"--\" id=\"s_382_n_3\"/>\n",
    "27444-            </node>\n",
    "27445-          </node>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anaphora_iter = tree.iter('anaphora')\n",
    "for anaphora in anaphora_iter:\n",
    "    # there's only one <relation> child element\n",
    "    antecedent = anaphora.getchildren()[0].attrib['antecedent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExportXML <element> meanings\n",
    "\n",
    "* `<node>`: a node in a syntax tree\n",
    "* `<word>`: a token in a sentence / syntax tree\n",
    "* `<relation>`: a child of an `<anaphora>` element; it's always a leaf node  \n",
    "   it has a `type` attrib (relation type) and an `antecedent` attrib (antecedent's node ID)  \n",
    "   NB: if an anaphora has no antecedent, (e.g. if it's an `expletive` relation) the `antecedent` attrib  \n",
    "   is an empty string!\n",
    "* `<anaphora>`: a child of a `<node>` or `<word>` element; always has one `<relation>` child;  \n",
    "  the element itself contains no information\n",
    "* `<sentence>`: a sentence / syntax tree\n",
    "\n",
    "```\n",
    " ('secedge', 4647),\n",
    " ('originDef', 2213),\n",
    " ('morphDef', 437),\n",
    " ('posDef', 56),\n",
    " ('edgeDef', 50),\n",
    " ('nodeDef', 29),\n",
    " ('editorDef', 26),\n",
    " ('secedgeDef', 7),\n",
    " ('comment', 6),\n",
    "\n",
    "\n",
    " ('posList', 1),\n",
    " ('secedgeList', 1),\n",
    " ('editorList', 1),\n",
    " ('edgeList', 1),\n",
    " ('originList', 1),\n",
    " ('format', 1),\n",
    " ('morphList', 1),\n",
    " ('nodeList', 1),\n",
    " ('export', 1)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_anaphora(anaphora, source_id):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    anaphora : etree.Element\n",
    "        an <anaphora> element\n",
    "    source_id : str\n",
    "        the node ID of the anaphora (points either to a <node> or a <word>)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    antecedent : str\n",
    "        node ID of the antecedent, e.g. ``s_4_n_527``\n",
    "    relation_type : str\n",
    "        anaphoric relation type, e.g. ``anaphoric`` or ``coreferential``\n",
    "    \"\"\"\n",
    "    # there's only one <relation> child element\n",
    "    relation = anaphora.getchildren()[0]\n",
    "    return relation.attrib['antecedent'], relation.attrib['type']\n",
    "    \n",
    "\n",
    "def exportxml2igraph(exportxml_file):\n",
    "    \"\"\"\n",
    "    TODO: add <node> and <word> attributes\n",
    "    \"\"\"\n",
    "    # in igraph, adding a single edge is prohibitively slow,\n",
    "    # as the whole index of the graph has to be rebuild!\n",
    "    # http://stackoverflow.com/questions/13974279/igraph-why-is-add-edge-function-so-slow-ompared-to-add-edges\n",
    "    # to speed this up, store the edges in a list & call add_edges() once!\n",
    "    edges = []\n",
    "    relations = {}\n",
    "    idocgraph = ig.Graph(directed=True)\n",
    "    \n",
    "    treeiter = etree.iterparse(TUEBADZ_FILE, tag='sentence')\n",
    "    for _action, sentence in treeiter:\n",
    "        sent_root_id = sentence.attrib['origin']\n",
    "        idocgraph.add_vertex(sent_root_id, label=sent_root_id)\n",
    "        \n",
    "        for element in sentence.iter('node', 'word', 'anaphora'):\n",
    "            parent_element = element.getparent()\n",
    "            # some <anaphora> are children of <word> elements\n",
    "            if parent_element.tag in ('node', 'word'):\n",
    "                parent_id = parent_element.attrib['id']\n",
    "            elif parent_element.tag == 'sentence':\n",
    "                parent_id = parent_element.attrib['origin']\n",
    "            else:\n",
    "                sys.stderr.write(\"Unexpected parent '{}' of element '{}'\\n\".format(parent_element, element))\n",
    "            element_id = element.attrib.get('id') # <anaphora> doesn't have an ID\n",
    "\n",
    "            if element.tag == 'node':\n",
    "                idocgraph.add_vertex(element_id, label=element.attrib['cat'])\n",
    "                edges.append((parent_id, element_id))\n",
    "            elif element.tag == 'word':\n",
    "                idocgraph.add_vertex(element_id, label=element.attrib['form'])\n",
    "                edges.append((parent_id, element_id))\n",
    "\n",
    "            else: # element.tag == 'anaphora'\n",
    "                # <anaphora> doesn't have an ID, but it's tied to its parent element\n",
    "                antecedent_str, relation_type = parse_anaphora(element, parent_id)\n",
    "                if antecedent_str:\n",
    "                    # there might be more than one antecedent\n",
    "                    for antecedent_id in antecedent_str.split(','):\n",
    "                        edge = (parent_id, antecedent_id)\n",
    "                        edges.append(edge)\n",
    "                        relations[edge] = relation_type\n",
    "                else:\n",
    "                    # there's no antecedent in case of an expletive anaphoric relation\n",
    "                    relations[(parent_id, None)] = relation_type\n",
    "      \n",
    "    idocgraph.add_edges(edges)\n",
    "\n",
    "    # igraph doesn't store nodes/edge names in a dict, so a lookup would be O(n)\n",
    "    node_name2id = {node['name']: node.index for node in idocgraph.vs}\n",
    "    edge_endpoints2id = {(edge.source, edge.target): edge.index\n",
    "                         for edge in idocgraph.es}\n",
    "\n",
    "    for (source, target) in relations:\n",
    "        relation_type = relations[(source, target)]\n",
    "        if target:\n",
    "            edge_endpoints = (node_name2id[source], node_name2id[target])\n",
    "            idocgraph.es[edge_endpoints2id[edge_endpoints]]['exportxml:relation_type'] = relation_type\n",
    "#             idocgraph.es[idocgraph.get_eid(source, target)]['exportxml:relation_type'] = relation_type\n",
    "\n",
    "        else:\n",
    "            # there's no antecedent in case of an expletive anaphoric relation\n",
    "            \n",
    "            idocgraph.vs[node_name2id[source]]['exportxml:anaphora_type'] = relation_type\n",
    "#             idocgraph.vs.select(name=source)['exportxml:anaphora_type'] = relation_type\n",
    "    return idocgraph\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 856 ms, total: 17.9 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tuebagraph = exportxml2igraph(TUEBADZ_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794461"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuebagraph.ecount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1787089"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuebagraph.vcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "foo = ig.Graph(directed=True)\n",
    "foo.add_vertices(['1','2','3','4'])\n",
    "foo.add_edges([('1', '1'), ('1', '2'), ('3', '4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "igraph.Edge(<igraph.Graph object at 0x5975af8>, 0, {})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for e in foo.es:\n",
    "#     print e, e.index, e.source, e.target\n",
    "foo.es[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "igraph.Vertex(<igraph.Graph object at 0x5975af8>,0,{'name': '1'}) 0 1\n",
      "igraph.Vertex(<igraph.Graph object at 0x5975af8>,1,{'name': '2'}) 1 2\n",
      "igraph.Vertex(<igraph.Graph object at 0x5975af8>,2,{'name': '3'}) 2 3\n",
      "igraph.Vertex(<igraph.Graph object at 0x5975af8>,3,{'name': '4'}) 3 4\n"
     ]
    }
   ],
   "source": [
    "for v in foo.vs:\n",
    "    print v, v.index, v['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<igraph.VertexSeq at 0xab9a83c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.vs.select(name='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "igraph.Vertex(<igraph.Graph object at 0x5975af8>,0,{'name': '1'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.vs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(foo.es.select(_source='3', _target='4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def exportxml2dict(exportxml_file):\n",
    "    nodes = []\n",
    "    edges = []\n",
    "    \n",
    "    itree = etree.iterparse(TUEBADZ_FILE, tag='sentence')\n",
    "    for _action, sentence in itree:\n",
    "        sent_root_id = sentence.attrib['origin']\n",
    "        nodes.append( (sent_root_id, sent_root_id) )\n",
    "        \n",
    "        for element in sentence.iter('node', 'word'):\n",
    "            parent_element = element.getparent()\n",
    "            if parent_element.tag == 'node':\n",
    "                parent_id = parent_element.attrib['id']\n",
    "            elif parent_element.tag == 'sentence':\n",
    "                parent_id = parent_element.attrib['origin']\n",
    "            else:\n",
    "                sys.stderr.write(\"Unexpected parent '{}' of element '{}'\\n\".format(parent_element, element))\n",
    "            element_id = element.attrib.get('id') # <anaphora> doesn't have an ID\n",
    "\n",
    "            if element.tag == 'node':\n",
    "                element_label = element.attrib['cat']\n",
    "            elif element.tag == 'word':\n",
    "                element_label = element.attrib['form']\n",
    "            else:\n",
    "                continue # for now, ignore other elements (e.g. <anaphora>)\n",
    "\n",
    "            nodes.append( (element_id, element_label) )\n",
    "            edges.append( (parent_id, element_id) )\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.99 s, sys: 620 ms, total: 6.61 s\n",
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nodes, edges = exportxml2dict(TUEBADZ_FILE) # 6.63s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## igraph: preprocessed node/edge lists, edges batch insert (total: 12.81 s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create node/edge lists\n",
    "- add nodes one by one\n",
    "- add edges in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "\n",
    "idocgraph = ig.Graph()\n",
    "for node_id, node_label in nodes:\n",
    "    idocgraph.add_vertex(node_id, label=node_label)\n",
    "idocgraph.add_edges(edges)\n",
    "```\n",
    "\n",
    "CPU times: user 6.06 s, sys: 112 ms, total: 6.18 s\n",
    "Wall time: 6.18 s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## igraph: preprocessed node/edge lists, nodes & edges batch insert (total: 7.85 s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create node/edge lists\n",
    "- add nodes in one go (without labels)\n",
    "- add edges in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%time\n",
    "\n",
    "idocgraph = ig.Graph()\n",
    "node_ids = (node_id for (node_id, node_label) in nodes)\n",
    "idocgraph.add_vertices(node_ids)\n",
    "idocgraph.add_edges(edges)\n",
    "```\n",
    "\n",
    "CPU times: user 1.16 s, sys: 60 ms, total: 1.22 s\n",
    "Wall time: 1.22 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## igraph: preprocessed node/edge lists, nodes/edges inserted iteratively (intractable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- added each node and edge one by one\n",
    "- took too long (killed after 10mins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%time\n",
    "\n",
    "idocgraph = ig.Graph()\n",
    "for node_id, node_label in nodes:\n",
    "    idocgraph.add_vertex(node_id, label=node_label)\n",
    "for source, target in edges:\n",
    "    # for each added edge, the whole index of the graph has to be rebuild!\n",
    "    # never do this for large graphs!\n",
    "    # http://stackoverflow.com/questions/13974279/igraph-why-is-add-edge-function-so-slow-ompared-to-add-edges\n",
    "    idocgraph.add_edge(source, target)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## igraph: combined preprocessing/inserting of nodes, edge caching/batch insert (total: 20.7s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "%%time\n",
    "tueba_igraph = exportxml2igraph(TUEBADZ_FILE)\n",
    "```\n",
    "\n",
    "CPU times: user 20.7 s, sys: 156 ms, total: 20.9 s\n",
    "Wall time: 20.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exportxml2docgraph(exportxml_file):\n",
    "    edges = []\n",
    "    docgraph = dg.DiscourseDocumentGraph()\n",
    "    edge_attribs = {'layers': {docgraph.ns}} # default edge attributes\n",
    "    \n",
    "    treeiter = etree.iterparse(TUEBADZ_FILE, tag='sentence')\n",
    "    for _action, sentence in treeiter:\n",
    "        sent_root_id = sentence.attrib['origin']\n",
    "        docgraph.add_node(sent_root_id, label=sent_root_id)\n",
    "        \n",
    "        for element in sentence.iter('node', 'word'):\n",
    "            parent_element = element.getparent()\n",
    "            if parent_element.tag == 'node':\n",
    "                parent_id = parent_element.attrib['id']\n",
    "            elif parent_element.tag == 'sentence':\n",
    "                parent_id = parent_element.attrib['origin']\n",
    "            else:\n",
    "                sys.stderr.write(\"Unexpected parent '{}' of element '{}'\\n\".format(parent_element, element))\n",
    "            element_id = element.attrib.get('id') # <anaphora> doesn't have an ID\n",
    "\n",
    "            if element.tag == 'node':\n",
    "                element_label = element.attrib['cat']\n",
    "            elif element.tag == 'word':\n",
    "                element_label = element.attrib['form']\n",
    "            else:\n",
    "                continue # for now, ignore other elements (e.g. <anaphora>)\n",
    "\n",
    "            docgraph.add_node(element_id, label=element_label)\n",
    "            edges.append((parent_id, element_id, edge_attribs))\n",
    "    docgraph.add_edges_from(edges)\n",
    "    return docgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## networkx: combined preprocessing/inserting of nodes, edge caching/batch insert (intractable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- killed process after 12 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use multiple cores by splitting exportxml file into 'documents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "treeiter = etree.iterparse(TUEBADZ_FILE, tag='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "documents = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.23 s, sys: 188 ms, total: 6.42 s\n",
      "Wall time: 6.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for _action, sentence in treeiter:\n",
    "    documents[sentence.attrib['origin']].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2213"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
