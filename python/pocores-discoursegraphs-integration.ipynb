{
 "metadata": {
  "name": "",
  "signature": "sha256:1ae5782ab3572c19799a8bccc6176d96f6c1f1d5112789227d4d53cbcbb3ccfc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "from pocores import Pocores, print_coreference_report\n",
      "from discoursegraphs.readwrite.mmax2 import spanstring2text, spanstring2tokens\n",
      "from discoursegraphs.readwrite import ConllDocumentGraph, MMAXDocumentGraph\n",
      "from discoursegraphs import get_pointing_chains, print_dot\n",
      "\n",
      "DOC_ID = 'maz-11299'\n",
      "\n",
      "cdg = ConllDocumentGraph(os.path.expanduser('~/repos/pocores/src/pocores/test/maz176/{}.conll2009'.format(DOC_ID)))\n",
      "mdg = MMAXDocumentGraph(os.path.expanduser('~/repos/pcc-annis-merged/maz176/coreference/{}.mmax'.format(DOC_ID)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %load_ext gvmagic\n",
      "# %dotstr print_dot(cdg)\n",
      "# %dotstr print_dot(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = Pocores(cdg)\n",
      "p.resolve_anaphora()\n",
      "p.add_coreference_chains_to_docgraph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[['s13_t7', 's3_t8'],\n",
        " ['s16_t13', 's5_t5'],\n",
        " ['s11_t8', 's4_t3'],\n",
        " ['s16_t10', 's16_t9'],\n",
        " ['s8_t46', 's8_t27'],\n",
        " ['s3_t1', 's2_t7'],\n",
        " ['s10_t7', 's1_t1'],\n",
        " ['s8_t1', 's6_t13'],\n",
        " ['s15_t6',\n",
        "  's15_t5',\n",
        "  's14_t5',\n",
        "  's11_t5',\n",
        "  's10_t2',\n",
        "  's9_t6',\n",
        "  's9_t5',\n",
        "  's8_t34',\n",
        "  's6_t5',\n",
        "  's3_t3',\n",
        "  's2_t2'],\n",
        " ['s13_t3', 's9_t2', 's8_t13']]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[['markable_100011', 'markable_3'],\n",
        " ['markable_18', 'markable_6'],\n",
        " ['markable_1000205', 'markable_1000200', 'markable_1000211'],\n",
        " ['markable_70',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000132', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_70',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000131', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_10', 'markable_1000206', 'markable_10004'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_24', 'markable_7'],\n",
        " ['markable_93', 'markable_16']]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "FIXME: MMAXDocumentGraph contains each token_id twice in .tokens and .get_tokens()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discoursegraphs as dg\n",
      "\n",
      "# mdg_tokens = list(mdg.get_tokens())\n",
      "# for i, (tid, tok) in enumerate(p.document.get_tokens()):\n",
      "#     print i, tid, tok, mdg_tokens[i][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oldtoks = list(p.document.get_tokens())\n",
      "newtoks = list(mdg.get_tokens())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(oldtoks), len(newtoks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(212, 212)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent_id in mdg.sentences:\n",
      "    print sent_id,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "markable_5000 markable_5001 markable_5002 markable_5003 markable_5004 markable_5005 markable_5006 markable_5007 markable_5008 markable_5009 markable_50010 markable_50011 markable_50012 markable_50013 markable_50014 markable_50015 markable_50016\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(mdg.tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "212"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tok_id in mdg.tokens:\n",
      "    print tok_id,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "word_1 word_2 word_3 word_4 word_5 word_6 word_7 word_8 word_9 word_10 word_11 word_12 word_13 word_14 word_15 word_16 word_17 word_18 word_19 word_20 word_21 word_22 word_23 word_24 word_25 word_26 word_27 word_28 word_29 word_30 word_31 word_32 word_33 word_34 word_35 word_36 word_37 word_38 word_39 word_40 word_41 word_42 word_43 word_44 word_45 word_46 word_47 word_48 word_49 word_50 word_51 word_52 word_53 word_54 word_55 word_56 word_57 word_58 word_59 word_60 word_61 word_62 word_63 word_64 word_65 word_66 word_67 word_68 word_69 word_70 word_71 word_72 word_73 word_74 word_75 word_76 word_77 word_78 word_79 word_80 word_81 word_82 word_83 word_84 word_85 word_86 word_87 word_88 word_89 word_90 word_91 word_92 word_93 word_94 word_95 word_96 word_97 word_98 word_99 word_100 word_101 word_102 word_103 word_104 word_105 word_106 word_107 word_108 word_109 word_110 word_111 word_112 word_113 word_114 word_115 word_116 word_117 word_118 word_119 word_120 word_121 word_122 word_123 word_124 word_125 word_126 word_127 word_128 word_129 word_130 word_131 word_132 word_133 word_134 word_135 word_136 word_137 word_138 word_139 word_140 word_141 word_142 word_143 word_144 word_145 word_146 word_147 word_148 word_149 word_150 word_151 word_152 word_153 word_154 word_155 word_156 word_157 word_158 word_159 word_160 word_161 word_162 word_163 word_164 word_165 word_166 word_167 word_168 word_169 word_170 word_171 word_172 word_173 word_174 word_175 word_176 word_177 word_178 word_179 word_180 word_181 word_182 word_183 word_184 word_185 word_186 word_187 word_188 word_189 word_190 word_191 word_192 word_193 word_194 word_195 word_196 word_197 word_198 word_199 word_200 word_201 word_202 word_203 word_204 word_205 word_206 word_207 word_208 word_209 word_210 word_211 word_212\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from discoursegraphs import create_token_mapping\n",
      "\n",
      "pocores2mmax = create_token_mapping(p.document, mdg)\n",
      "mmax2pocores = create_token_mapping(mdg, p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdg.merge_graphs(p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[['word_166', 'word_129', 'word_90'],\n",
        " ['word_143', 'word_1'],\n",
        " ['word_10', 'word_8'],\n",
        " ['word_201', 'word_200'],\n",
        " ['word_78', 'word_60'],\n",
        " ['markable_18', 'markable_6'],\n",
        " ['markable_10', 'markable_1000206', 'markable_10004'],\n",
        " ['markable_70',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000132', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_70',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000131', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_93', 'markable_16'],\n",
        " ['markable_100011', 'markable_3'],\n",
        " ['word_170', 'word_17'],\n",
        " ['markable_1000205', 'markable_1000200', 'markable_1000211'],\n",
        " ['word_153', 'word_23'],\n",
        " ['word_186',\n",
        "  'word_185',\n",
        "  'word_178',\n",
        "  'word_150',\n",
        "  'word_138',\n",
        "  'word_133',\n",
        "  'word_132',\n",
        "  'word_111',\n",
        "  'word_52',\n",
        "  'word_12',\n",
        "  'word_3'],\n",
        " ['word_204', 'word_37'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_24', 'markable_7'],\n",
        " ['word_123', 'word_104']]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg, layer='mmax')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[['markable_100011', 'markable_3'],\n",
        " ['markable_18', 'markable_6'],\n",
        " ['markable_1000205', 'markable_1000200', 'markable_1000211'],\n",
        " ['markable_70',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000132', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_70',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000131', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_10', 'markable_1000206', 'markable_10004'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_24', 'markable_7'],\n",
        " ['markable_93', 'markable_16']]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg, layer='pocores')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "[['word_170', 'word_17'],\n",
        " ['word_143', 'word_1'],\n",
        " ['word_78', 'word_60'],\n",
        " ['word_153', 'word_23'],\n",
        " ['word_186',\n",
        "  'word_185',\n",
        "  'word_178',\n",
        "  'word_150',\n",
        "  'word_138',\n",
        "  'word_133',\n",
        "  'word_132',\n",
        "  'word_111',\n",
        "  'word_52',\n",
        "  'word_12',\n",
        "  'word_3'],\n",
        " ['word_201', 'word_200'],\n",
        " ['word_10', 'word_8'],\n",
        " ['word_123', 'word_104'],\n",
        " ['word_166', 'word_129', 'word_90'],\n",
        " ['word_204', 'word_37']]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg, layer='pocores'):\n",
      "    print list(p._get_wordlist(chain, verbose=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'Runde', 'word_170'), (u'Runde', 'word_17')]\n",
        "[(u'Feigenblatt', 'word_143'), (u'Feigenblatt', 'word_1')]\n",
        "[(u'Es', 'word_78'), (u'Wort', 'word_60')]\n",
        "[(u'Politiker', 'word_153'), (u'Politiker', 'word_23')]\n",
        "[(u'sich', 'word_186'), (u'sie', 'word_185'), (u'Jugendliche', 'word_178'), (u'ihnen', 'word_150'), (u'Jugendlichen', 'word_138'), (u'ihnen', 'word_133'), (u'sie', 'word_132'), (u'Jugendliche', 'word_111'), (u'Jugendlichen', 'word_52'), (u'sie', 'word_12'), (u'Jugendlichen', 'word_3')]\n",
        "[(u'ihren', 'word_201'), (u'Gewerbeverein', 'word_200')]\n",
        "[(u'Das', 'word_10'), (u'Musikcaf\\xe9', 'word_8')]\n",
        "[(u'sie', 'word_123'), (u'SPD', 'word_104')]\n",
        "[(u'es', 'word_166'), (u'das', 'word_129'), (u'Andrae', 'word_90')]\n",
        "[(u'Rathaus', 'word_204'), (u'Rathaus', 'word_37')]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg, layer='mmax'):\n",
      "    print [(spanstring2text(mdg,mdg.node[node_id]['mmax:span']), node_id) for node_id in chain]        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'sie', 'markable_100011'), (u'Die Jugendlichen in Zossen', 'markable_3')]\n",
        "[(u'Mit dem Treffen im Rathaus', 'markable_18'), (u'bei der ersten Zossener Runde', 'markable_6')]\n",
        "[(u'Die', 'markable_1000205'), (u'ihren', 'markable_1000200'), (u'Vertreter von PDS und Gewerbeverein', 'markable_1000211')]\n",
        "[(u'die Politiker', 'markable_70'), (u'ihnen', 'markable_1000132'), (u'sie', 'markable_1000122'), (u'die beiden geladenen Jugendlichen', 'markable_23'), (u'Die Jugendlichen in Zossen', 'markable_3')]\n",
        "[(u'die Politiker', 'markable_70'), (u'ihnen', 'markable_1000132'), (u'Karola Andrae ( B\\xfcrgerb\\xfcndnis/FDP ) , Susanne Michler ( CDU ) und Joachim Zanow ( SPD', 'markable_1000207'), (u'drei Erwachsene', 'markable_1000208')]\n",
        "[(u'die Politiker', 'markable_70'), (u'sie', 'markable_1000131'), (u'sie', 'markable_1000122'), (u'die beiden geladenen Jugendlichen', 'markable_23'), (u'Die Jugendlichen in Zossen', 'markable_3')]\n",
        "[(u'die Politiker', 'markable_70'), (u'sie', 'markable_1000131'), (u'Karola Andrae ( B\\xfcrgerb\\xfcndnis/FDP ) , Susanne Michler ( CDU ) und Joachim Zanow ( SPD', 'markable_1000207'), (u'drei Erwachsene', 'markable_1000208')]\n",
        "[(u'der Stadt', 'markable_10'), (u'Zossener', 'markable_1000206'), (u'in Zossen', 'markable_10004')]\n",
        "[(u'sie', 'markable_1000184'), (u'mit ihnen', 'markable_1000149'), (u'Die Jugendlichen', 'markable_63'), (u'ihnen', 'markable_1000132'), (u'sie', 'markable_1000122'), (u'die beiden geladenen Jugendlichen', 'markable_23'), (u'Die Jugendlichen in Zossen', 'markable_3')]\n",
        "[(u'sie', 'markable_1000184'), (u'mit ihnen', 'markable_1000149'), (u'Die Jugendlichen', 'markable_63'), (u'ihnen', 'markable_1000132'), (u'Karola Andrae ( B\\xfcrgerb\\xfcndnis/FDP ) , Susanne Michler ( CDU ) und Joachim Zanow ( SPD', 'markable_1000207'), (u'drei Erwachsene', 'markable_1000208')]\n",
        "[(u'sie', 'markable_1000184'), (u'mit ihnen', 'markable_1000149'), (u'Die Jugendlichen', 'markable_63'), (u'sie', 'markable_1000131'), (u'sie', 'markable_1000122'), (u'die beiden geladenen Jugendlichen', 'markable_23'), (u'Die Jugendlichen in Zossen', 'markable_3')]\n",
        "[(u'sie', 'markable_1000184'), (u'mit ihnen', 'markable_1000149'), (u'Die Jugendlichen', 'markable_63'), (u'sie', 'markable_1000131'), (u'Karola Andrae ( B\\xfcrgerb\\xfcndnis/FDP ) , Susanne Michler ( CDU ) und Joachim Zanow ( SPD', 'markable_1000207'), (u'drei Erwachsene', 'markable_1000208')]\n",
        "[(u'des Abends', 'markable_24'), (u'am Dienstagabend', 'markable_7')]\n",
        "[(u'ins Rathaus', 'markable_93'), (u'im Rathaus', 'markable_16')]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pocores_chains = get_pointing_chains(mdg, layer='pocores')\n",
      "mmax_chains = get_pointing_chains(mdg, layer='mmax')\n",
      "\n",
      "for chain in mmax_chains:\n",
      "    for node_id in chain:\n",
      "        span_str = mdg.node[node_id]['mmax:span']\n",
      "        markable_was_found = any([token_id in chain\n",
      "                               for token_id in spanstring2tokens(span_str)\n",
      "                               for chain in pocores_chains])\n",
      "        \n",
      "        # at least one word in this markable was found by pocores\n",
      "        markable_str = spanstring2text(mdg, span_str)\n",
      "#         print markable_str, markable_was_found\n",
      "        if not markable_was_found:\n",
      "            markable_was_considered = any(mmax2pocores[mmax_token_id] in p.candidate_report\n",
      "                                          for mmax_token_id in spanstring2tokens(span_str))\n",
      "            if not markable_was_considered:\n",
      "                print (\"No word from the markable '{}' ({} - {}) \"\n",
      "                       \"was even considered as an anaphora\".format(markable_str, node_id, span_str))\n",
      "            else:\n",
      "                for mmax_token_id in spanstring2tokens(span_str):\n",
      "                    if mmax2pocores[mmax_token_id] in p.candidate_report:\n",
      "                        report = p.candidate_report[mmax2pocores[mmax_token_id]]\n",
      "                        if report['anaphora_type'] == 'pronominal':\n",
      "                            print \"Candidate was falsely rejected.\"\n",
      "                            print p.candidate_report[mmax2pocores[mmax_token_id]]\n",
      "        \n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "No word from the markable 'Die' (markable_1000205 - word_206) was even considered as an anaphora\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "No word from the markable 'Zossener' (markable_1000206 - word_16) was even considered as an anaphora\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ana in p.candidate_report:\n",
      "    if p.candidate_report[ana]['anaphora_type'] == 'pronominal':\n",
      "        print ana, p.candidate_report[ana]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "s9_t5 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s5_t13', 's6_t5', 's8_t10', 's8_t34'], 'filter_results': OrderedDict([('distance', (['s5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s5_t13', 's6_t5', 's8_t10', 's8_t34'], ', which are in morphological agreement with the anaphora')), ('binding', (['s5_t13', 's6_t5', 's8_t10', 's8_t34'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2']})\n",
        "s13_t3 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s9_t2'], 'filter_results': OrderedDict([('distance', (['s9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7', 's11_t5', 's11_t8', 's12_t5'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7', 's11_t5', 's11_t8', 's12_t5'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s9_t2'], ', which are in morphological agreement with the anaphora')), ('binding', (['s9_t2'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7', 's11_t5', 's11_t8', 's12_t5']})\n",
        "s9_t2 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s5_t3', 's5_t5', 's6_t13', 's8_t1', 's8_t13'], 'filter_results': OrderedDict([('distance', (['s5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s5_t3', 's5_t5', 's6_t13', 's8_t1', 's8_t13'], ', which are in morphological agreement with the anaphora')), ('binding', (['s5_t3', 's5_t5', 's6_t13', 's8_t1', 's8_t13'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46']})\n",
        "s11_t5 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s8_t10', 's8_t34', 's9_t5', 's9_t6', 's10_t2'], 'filter_results': OrderedDict([('distance', (['s8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s8_t1', 's8_t5', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s8_t10', 's8_t34', 's9_t5', 's9_t6', 's10_t2'], ', which are in morphological agreement with the anaphora')), ('binding', (['s8_t10', 's8_t34', 's9_t5', 's9_t6', 's10_t2'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7']})\n",
        "s16_t10 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s13_t8', 's16_t9'], 'filter_results': OrderedDict([('distance', (['s12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3', 's15_t5', 's15_t6', 's15_t9', 's16_t5', 's16_t7', 's16_t9'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3', 's15_t5', 's15_t9', 's16_t5', 's16_t7', 's16_t9'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s13_t8', 's16_t9'], ', which are in morphological agreement with the anaphora')), ('binding', (['s13_t8', 's16_t9'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7', 's11_t5', 's11_t8', 's12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3', 's15_t5', 's15_t6', 's15_t9', 's16_t5', 's16_t7', 's16_t9']})\n",
        "s8_t46 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s4_t5', 's6_t20', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t27'], 'filter_results': OrderedDict([('distance', (['s4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s4_t5', 's6_t20', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t27', 's8_t42'], ', which are in morphological agreement with the anaphora')), ('binding', (['s4_t5', 's6_t20', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t27'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42']})\n",
        "s8_t1 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s4_t7', 's5_t3', 's5_t5', 's6_t13'], 'filter_results': OrderedDict([('distance', (['s4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s4_t7', 's5_t3', 's5_t5', 's6_t13'], ', which are in morphological agreement with the anaphora')), ('binding', (['s4_t7', 's5_t3', 's5_t5', 's6_t13'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20']})\n",
        "s15_t6 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s15_t5'], 'filter_results': OrderedDict([('distance', (['s11_t5', 's11_t8', 's12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3', 's15_t5'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s11_t5', 's11_t8', 's12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3', 's15_t5'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s11_t5', 's11_t8', 's14_t5', 's15_t5'], ', which are in morphological agreement with the anaphora')), ('binding', (['s15_t5'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7', 's11_t5', 's11_t8', 's12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3', 's15_t5']})\n",
        "s8_t8 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': [], 'filter_results': OrderedDict([('distance', (['s4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s4_t3', 's5_t13', 's6_t5'], ', which are in morphological agreement with the anaphora')), ('binding', ([], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5']})\n",
        "s15_t5 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s11_t5', 's11_t8', 's14_t5'], 'filter_results': OrderedDict([('distance', (['s11_t5', 's11_t8', 's12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s11_t5', 's11_t8', 's12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s11_t5', 's11_t8', 's14_t5'], ', which are in morphological agreement with the anaphora')), ('binding', (['s11_t5', 's11_t8', 's14_t5'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5', 's9_t6', 's10_t2', 's10_t7', 's11_t5', 's11_t8', 's12_t5', 's13_t3', 's13_t7', 's13_t8', 's14_t5', 's15_t3']})\n",
        "s9_t6 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s8_t10', 's8_t34', 's9_t5'], 'filter_results': OrderedDict([('distance', (['s5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s8_t10', 's8_t34', 's9_t5'], ', which are in morphological agreement with the anaphora')), ('binding', (['s8_t10', 's8_t34', 's9_t5'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1', 's3_t3', 's3_t8', 's3_t10', 's4_t3', 's4_t5', 's4_t7', 's5_t3', 's5_t5', 's5_t10', 's5_t13', 's6_t5', 's6_t7', 's6_t9', 's6_t13', 's6_t20', 's8_t1', 's8_t5', 's8_t8', 's8_t10', 's8_t13', 's8_t15', 's8_t19', 's8_t21', 's8_t25', 's8_t27', 's8_t34', 's8_t42', 's8_t46', 's9_t2', 's9_t5']})\n",
        "s3_t1 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s1_t1', 's2_t4', 's2_t7'], 'filter_results': OrderedDict([('distance', (['s1_t1', 's2_t2', 's2_t4', 's2_t7'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s1_t1', 's2_t2', 's2_t4', 's2_t7'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s1_t1', 's2_t4', 's2_t7'], ', which are in morphological agreement with the anaphora')), ('binding', (['s1_t1', 's2_t4', 's2_t7'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7']})\n",
        "s3_t3 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s2_t2'], 'filter_results': OrderedDict([('distance', (['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s2_t2'], ', which are in morphological agreement with the anaphora')), ('binding', (['s2_t2'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t1', 's2_t2', 's2_t4', 's2_t7', 's3_t1']})\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg):\n",
      "    for node_id in chain:\n",
      "        print node_id, spanstring2text(mdg, mdg.node[node_id]['mmax:span'])\n",
      "        print '\\t', mdg.node[node_id]['mmax:type']\n",
      "    print '\\n'\n",
      "    \n",
      "\n",
      "for chain in get_pointing_chains(p.document):\n",
      "    for node_id in chain:\n",
      "        print node_id,\n",
      "        print '\\t', p.document.node[node_id]['pocores:type']\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "word_166"
       ]
      },
      {
       "ename": "KeyError",
       "evalue": "'mmax:span'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-21-6aa46bf95fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchain\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_pointing_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mprint\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspanstring2text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mmax:span'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mmax:type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'mmax:span'"
       ]
      }
     ],
     "prompt_number": 21
    }
   ],
   "metadata": {}
  }
 ]
}