{
 "metadata": {
  "name": "",
  "signature": "sha256:d7d535cbfac8756f575d2c8411eafb3d19f6d64da2bfc820c33e16d0ab6c64ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "from pocores import Pocores, print_coreference_report\n",
      "from discoursegraphs.readwrite.mmax2 import spanstring2text, spanstring2tokens\n",
      "from discoursegraphs.readwrite import ConllDocumentGraph, MMAXDocumentGraph\n",
      "from discoursegraphs import get_pointing_chains\n",
      "\n",
      "DOC_ID = 'maz-1423'\n",
      "\n",
      "cdg = ConllDocumentGraph(os.path.expanduser('~/repos/pocores/src/pocores/test/maz176/{}.conll2009'.format(DOC_ID)))\n",
      "mdg = MMAXDocumentGraph(os.path.expanduser('~/repos/pcc-annis-merged/maz176/coreference/{}.mmax'.format(DOC_ID)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = Pocores(cdg)\n",
      "p.resolve_anaphora()\n",
      "p.add_coreference_chains_to_docgraph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "[['s11_t5', 's4_t4', 's2_t13'],\n",
        " ['s7_t3', 's5_t7'],\n",
        " ['s16_t5', 's14_t14', 's13_t7', 's12_t4', 's12_t1'],\n",
        " ['s16_t3', 's9_t2', 's7_t8'],\n",
        " ['s15_t12', 's6_t6'],\n",
        " ['s15_t15', 's11_t7']]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[['markable_22',\n",
        "  'markable_19',\n",
        "  'markable_17',\n",
        "  'markable_14',\n",
        "  'markable_12',\n",
        "  'markable_11'],\n",
        " ['markable_21', 'markable_10', 'markable_8', 'markable_7', 'markable_2']]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from discoursegraphs import create_token_mapping\n",
      "\n",
      "pocores2mmax = create_token_mapping(p.document, mdg)\n",
      "mmax2pocores = create_token_mapping(mdg, p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdg.merge_graphs(p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[['word_112', 'word_37', 'word_15'],\n",
        " ['word_170', 'word_114'],\n",
        " ['word_167', 'word_63'],\n",
        " ['word_180', 'word_149', 'word_131', 'word_119', 'word_116'],\n",
        " ['markable_22',\n",
        "  'markable_19',\n",
        "  'markable_17',\n",
        "  'markable_14',\n",
        "  'markable_12',\n",
        "  'markable_11'],\n",
        " ['markable_21', 'markable_10', 'markable_8', 'markable_7', 'markable_2'],\n",
        " ['word_178', 'word_95', 'word_74'],\n",
        " ['word_69', 'word_52']]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg, layer='mmax')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "[['markable_22',\n",
        "  'markable_19',\n",
        "  'markable_17',\n",
        "  'markable_14',\n",
        "  'markable_12',\n",
        "  'markable_11'],\n",
        " ['markable_21', 'markable_10', 'markable_8', 'markable_7', 'markable_2']]"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg, layer='pocores')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[['word_170', 'word_114'],\n",
        " ['word_112', 'word_37', 'word_15'],\n",
        " ['word_167', 'word_63'],\n",
        " ['word_180', 'word_149', 'word_131', 'word_119', 'word_116'],\n",
        " ['word_178', 'word_95', 'word_74'],\n",
        " ['word_69', 'word_52']]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg, layer='pocores'):\n",
      "    print list(p._get_wordlist(chain, verbose=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'Platz', 'word_170'), (u'Platz', 'word_114')]\n",
        "[(u'Veranstaltern', 'word_112'), (u'Veranstalter', 'word_37'), (u'Veranstalter', 'word_15')]\n",
        "[(u'Veranstaltungsort', 'word_167'), (u'Veranstaltungsort', 'word_63')]\n",
        "[(u'Wittstock', 'word_180'), (u'Wittstock', 'word_149'), (u'es', 'word_131'), (u'sich', 'word_119'), (u'Wittstock', 'word_116')]\n",
        "[(u'Halle', 'word_178'), (u'Halle', 'word_95'), (u'Halle', 'word_74')]\n",
        "[(u'es', 'word_69'), (u'Tropfen', 'word_52')]\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg, layer='mmax'):\n",
      "    print [(spanstring2text(mdg,mdg.node[node_id]['mmax:span']), node_id) for node_id in chain]        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'Wittstock', 'markable_22'), (u'die Dosse-Stadt', 'markable_19'), (u'Wittstock', 'markable_17'), (u'Wittstock', 'markable_14'), (u'in der Region', 'markable_12'), (u'Wittstocker', 'markable_11')]\n",
        "[(u'die Halle', 'markable_21'), (u'Die Halle', 'markable_10'), (u'die Halle', 'markable_8'), (u'f\\xfcr den schmucken Veranstaltungsort', 'markable_7'), (u'die neue Wittstocker Stadthalle', 'markable_2')]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pocores_chains = get_pointing_chains(mdg, layer='pocores')\n",
      "mmax_chains = get_pointing_chains(mdg, layer='mmax')\n",
      "\n",
      "for chain in mmax_chains:\n",
      "    for node_id in chain:\n",
      "        span_str = mdg.node[node_id]['mmax:span']\n",
      "        markable_was_found = any([token_id in chain\n",
      "                               for token_id in spanstring2tokens(span_str)\n",
      "                               for chain in pocores_chains])\n",
      "        \n",
      "        # at least one word in this markable was found by pocores\n",
      "        markable_str = spanstring2text(mdg, span_str)\n",
      "#         print markable_str, markable_was_found\n",
      "        if not markable_was_found:\n",
      "            markable_was_considered = any(mmax2pocores[mmax_token_id] in p.candidate_report\n",
      "                                          for mmax_token_id in spanstring2tokens(span_str))\n",
      "            if not markable_was_considered:\n",
      "                print (\"No word from the markable '{}' ({} - {}) \"\n",
      "                       \"was even considered as an anaphora\".format(markable_str, node_id, span_str))\n",
      "            else:\n",
      "                for mmax_token_id in spanstring2tokens(span_str):\n",
      "                    if mmax2pocores[mmax_token_id] in p.candidate_report:\n",
      "                        report = p.candidate_report[mmax2pocores[mmax_token_id]]\n",
      "                        if report['anaphora_type'] == 'pronominal':\n",
      "                            print \"Candidate was falsely rejected.\"\n",
      "                            print p.candidate_report[mmax2pocores[mmax_token_id]]\n",
      "        \n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "No word from the markable 'Wittstocker' (markable_11 - word_10) was even considered as an anaphora\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ana in p.candidate_report:\n",
      "    if p.candidate_report[ana]['anaphora_type'] == 'pronominal':\n",
      "        print ana, p.candidate_report[ana]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "s7_t3 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s5_t7'], 'filter_results': OrderedDict([('distance', (['s3_t4', 's3_t7', 's4_t4', 's4_t10', 's5_t2', 's5_t7', 's5_t11', 's6_t2', 's6_t6'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s3_t4', 's3_t7', 's4_t4', 's4_t10', 's5_t2', 's5_t7', 's5_t11', 's6_t2', 's6_t6'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s5_t7'], ', which are in morphological agreement with the anaphora')), ('binding', (['s5_t7'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t2', 's2_t2', 's2_t9', 's2_t11', 's2_t13', 's2_t18', 's2_t20', 's3_t4', 's3_t7', 's4_t4', 's4_t10', 's5_t2', 's5_t7', 's5_t11', 's6_t2', 's6_t6']})\n",
        "s13_t7 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s12_t1'], 'filter_results': OrderedDict([('distance', (['s9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1', 's12_t4', 's12_t7', 's13_t2'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1', 's12_t7', 's13_t2'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s12_t1', 's13_t2'], ', which are in morphological agreement with the anaphora')), ('binding', (['s12_t1'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t2', 's2_t2', 's2_t9', 's2_t11', 's2_t13', 's2_t18', 's2_t20', 's3_t4', 's3_t7', 's4_t4', 's4_t10', 's5_t2', 's5_t7', 's5_t11', 's6_t2', 's6_t6', 's7_t3', 's7_t8', 's8_t3', 's8_t10', 's9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1', 's12_t4', 's12_t7', 's13_t2']})\n",
        "s14_t8 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': [], 'filter_results': OrderedDict([('distance', (['s10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1', 's12_t4', 's12_t7', 's13_t2', 's13_t7', 's13_t9', 's14_t2'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1', 's12_t7', 's13_t2', 's13_t7', 's13_t9', 's14_t2'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s11_t5'], ', which are in morphological agreement with the anaphora')), ('binding', ([], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t2', 's2_t2', 's2_t9', 's2_t11', 's2_t13', 's2_t18', 's2_t20', 's3_t4', 's3_t7', 's4_t4', 's4_t10', 's5_t2', 's5_t7', 's5_t11', 's6_t2', 's6_t6', 's7_t3', 's7_t8', 's8_t3', 's8_t10', 's9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1', 's12_t4', 's12_t7', 's13_t2', 's13_t7', 's13_t9', 's14_t2']})\n",
        "s12_t4 defaultdict(<type 'str'>, {'anaphora_type': 'pronominal', 'filtered_candidates': ['s12_t1'], 'filter_results': OrderedDict([('distance', (['s8_t3', 's8_t10', 's9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1'], 'Candidates mentioned no more than 4 sentences ago')), ('non_reflexive', (['s8_t3', 's8_t10', 's9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1'], \", which also don't represent reflexive personal pronouns, e.g. sich, einander, dich, mir\")), ('agreement', (['s8_t10', 's9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t7', 's12_t1'], ', which are in morphological agreement with the anaphora')), ('binding', (['s12_t1'], 'and which can be bound by the anaphora'))]), 'candidates': ['s1_t2', 's2_t2', 's2_t9', 's2_t11', 's2_t13', 's2_t18', 's2_t20', 's3_t4', 's3_t7', 's4_t4', 's4_t10', 's5_t2', 's5_t7', 's5_t11', 's6_t2', 's6_t6', 's7_t3', 's7_t8', 's8_t3', 's8_t10', 's9_t2', 's10_t4', 's10_t7', 's11_t3', 's11_t5', 's11_t7', 's12_t1']})\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg):\n",
      "    for node_id in chain:\n",
      "        print node_id, spanstring2text(mdg, mdg.node[node_id]['mmax:span'])\n",
      "        print '\\t', mdg.node[node_id]['mmax:type']\n",
      "    print '\\n'\n",
      "    \n",
      "\n",
      "for chain in get_pointing_chains(p.document):\n",
      "    for node_id in chain:\n",
      "        print node_id,\n",
      "        print '\\t', p.document.node[node_id]['pocores:type']\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "word_112"
       ]
      },
      {
       "ename": "KeyError",
       "evalue": "'mmax:span'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-31-6aa46bf95fcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchain\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_pointing_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mprint\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspanstring2text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mmax:span'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mmax:type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyError\u001b[0m: 'mmax:span'"
       ]
      }
     ],
     "prompt_number": 31
    }
   ],
   "metadata": {}
  }
 ]
}