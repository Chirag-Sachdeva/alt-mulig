{
 "metadata": {
  "name": "",
  "signature": "sha256:705cccbebf53473ca6e1f054a1876c92c03165735bb4272503f34c4793e0a68e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "from pocores import Pocores, print_coreference_report\n",
      "from discoursegraphs.readwrite.mmax2 import spanstring2text, spanstring2tokens\n",
      "from discoursegraphs.readwrite import ConllDocumentGraph, MMAXDocumentGraph\n",
      "from discoursegraphs import get_pointing_chains, print_dot\n",
      "\n",
      "DOC_ID = 'maz-11299'\n",
      "\n",
      "cdg = ConllDocumentGraph(os.path.expanduser('~/repos/pocores/src/pocores/test/maz176/{}.conll2009'.format(DOC_ID)))\n",
      "mdg = MMAXDocumentGraph(os.path.expanduser('~/repos/pcc-annis-merged/maz176/coreference/{}.mmax'.format(DOC_ID)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# %load_ext gvmagic\n",
      "# %dotstr print_dot(cdg)\n",
      "# %dotstr print_dot(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = Pocores(cdg)\n",
      "p.resolve_anaphora()\n",
      "p.add_coreference_chains_to_docgraph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[['s13_t7', 's3_t8'],\n",
        " ['s16_t13', 's5_t5'],\n",
        " ['s11_t8', 's4_t3'],\n",
        " ['s16_t10', 's16_t9'],\n",
        " ['s8_t46', 's8_t27'],\n",
        " ['s3_t1', 's2_t7'],\n",
        " ['s10_t7', 's1_t1'],\n",
        " ['s8_t1', 's6_t13'],\n",
        " ['s15_t6',\n",
        "  's15_t5',\n",
        "  's14_t5',\n",
        "  's11_t5',\n",
        "  's10_t2',\n",
        "  's9_t6',\n",
        "  's9_t5',\n",
        "  's8_t34',\n",
        "  's6_t5',\n",
        "  's3_t3',\n",
        "  's2_t2'],\n",
        " ['s13_t3', 's9_t2', 's8_t13']]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[['markable_100011', 'markable_3'],\n",
        " ['markable_18', 'markable_6'],\n",
        " ['markable_1000205', 'markable_1000200', 'markable_1000211'],\n",
        " ['markable_70',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000132', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_70',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_70', 'markable_1000131', 'markable_1000207', 'markable_1000208'],\n",
        " ['markable_10', 'markable_1000206', 'markable_10004'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000132',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000122',\n",
        "  'markable_23',\n",
        "  'markable_3'],\n",
        " ['markable_1000184',\n",
        "  'markable_1000149',\n",
        "  'markable_63',\n",
        "  'markable_1000131',\n",
        "  'markable_1000207',\n",
        "  'markable_1000208'],\n",
        " ['markable_24', 'markable_7'],\n",
        " ['markable_93', 'markable_16']]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "FIXME: MMAXDocumentGraph contains each token_id twice in .tokens and .get_tokens()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import discoursegraphs as dg\n",
      "\n",
      "# mdg_tokens = list(mdg.get_tokens())\n",
      "# for i, (tid, tok) in enumerate(p.document.get_tokens()):\n",
      "#     print i, tid, tok, mdg_tokens[i][1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oldtoks = list(p.document.get_tokens())\n",
      "newtoks = list(mdg.get_tokens())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(oldtoks), len(newtoks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "(212, 424)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent_id in mdg.sentences:\n",
      "    print sent_id,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "markable_5000 markable_5001 markable_5002 markable_5003 markable_5004 markable_5005 markable_5006 markable_5007 markable_5008 markable_5009 markable_50010 markable_50011 markable_50012 markable_50013 markable_50014 markable_50015 markable_50016\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(mdg.tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "424"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for tok_id in mdg.tokens:\n",
      "    print tok_id,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "word_1 word_2 word_3 word_4 word_5 word_6 word_7 word_8 word_9 word_10 word_11 word_12 word_13 word_14 word_15 word_16 word_17 word_18 word_19 word_20 word_21 word_22 word_23 word_24 word_25 word_26 word_27 word_28 word_29 word_30 word_31 word_32 word_33 word_34 word_35 word_36 word_37 word_38 word_39 word_40 word_41 word_42 word_43 word_44 word_45 word_46 word_47 word_48 word_49 word_50 word_51 word_52 word_53 word_54 word_55 word_56 word_57 word_58 word_59 word_60 word_61 word_62 word_63 word_64 word_65 word_66 word_67 word_68 word_69 word_70 word_71 word_72 word_73 word_74 word_75 word_76 word_77 word_78 word_79 word_80 word_81 word_82 word_83 word_84 word_85 word_86 word_87 word_88 word_89 word_90 word_91 word_92 word_93 word_94 word_95 word_96 word_97 word_98 word_99 word_100 word_101 word_102 word_103 word_104 word_105 word_106 word_107 word_108 word_109 word_110 word_111 word_112 word_113 word_114 word_115 word_116 word_117 word_118 word_119 word_120 word_121 word_122 word_123 word_124 word_125 word_126 word_127 word_128 word_129 word_130 word_131 word_132 word_133 word_134 word_135 word_136 word_137 word_138 word_139 word_140 word_141 word_142 word_143 word_144 word_145 word_146 word_147 word_148 word_149 word_150 word_151 word_152 word_153 word_154 word_155 word_156 word_157 word_158 word_159 word_160 word_161 word_162 word_163 word_164 word_165 word_166 word_167 word_168 word_169 word_170 word_171 word_172 word_173 word_174 word_175 word_176 word_177 word_178 word_179 word_180 word_181 word_182 word_183 word_184 word_185 word_186 word_187 word_188 word_189 word_190 word_191 word_192 word_193 word_194 word_195 word_196 word_197 word_198 word_199 word_200 word_201 word_202 word_203 word_204 word_205 word_206 word_207 word_208 word_209 word_210 word_211 word_212 word_1 word_2 word_3 word_4 word_5 word_6 word_7 word_8 word_9 word_10 word_11 word_12 word_13 word_14 word_15 word_16 word_17 word_18 word_19 word_20 word_21 word_22 word_23 word_24 word_25 word_26 word_27 word_28 word_29 word_30 word_31 word_32 word_33 word_34 word_35 word_36 word_37 word_38 word_39 word_40 word_41 word_42 word_43 word_44 word_45 word_46 word_47 word_48 word_49 word_50 word_51 word_52 word_53 word_54 word_55 word_56 word_57 word_58 word_59 word_60 word_61 word_62 word_63 word_64 word_65 word_66 word_67 word_68 word_69 word_70 word_71 word_72 word_73 word_74 word_75 word_76 word_77 word_78 word_79 word_80 word_81 word_82 word_83 word_84 word_85 word_86 word_87 word_88 word_89 word_90 word_91 word_92 word_93 word_94 word_95 word_96 word_97 word_98 word_99 word_100 word_101 word_102 word_103 word_104 word_105 word_106 word_107 word_108 word_109 word_110 word_111 word_112 word_113 word_114 word_115 word_116 word_117 word_118 word_119 word_120 word_121 word_122 word_123 word_124 word_125 word_126 word_127 word_128 word_129 word_130 word_131 word_132 word_133 word_134 word_135 word_136 word_137 word_138 word_139 word_140 word_141 word_142 word_143 word_144 word_145 word_146 word_147 word_148 word_149 word_150 word_151 word_152 word_153 word_154 word_155 word_156 word_157 word_158 word_159 word_160 word_161 word_162 word_163 word_164 word_165 word_166 word_167 word_168 word_169 word_170 word_171 word_172 word_173 word_174 word_175 word_176 word_177 word_178 word_179 word_180 word_181 word_182 word_183 word_184 word_185 word_186 word_187 word_188 word_189 word_190 word_191 word_192 word_193 word_194 word_195 word_196 word_197 word_198 word_199 word_200 word_201 word_202 word_203 word_204 word_205 word_206 word_207 word_208 word_209 word_210 word_211 word_212\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from discoursegraphs import create_token_mapping\n",
      "\n",
      "pocores2mmax = create_token_mapping(p.document, mdg)\n",
      "mmax2pocores = create_token_mapping(mdg, p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "StopIteration",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-32-f42f82e2214a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdiscoursegraphs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_token_mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpocores2mmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_token_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmmax2pocores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_token_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/discoursegraphs-0.1.2-py2.7.egg/discoursegraphs/discoursegraph.pyc\u001b[0m in \u001b[0;36mcreate_token_mapping\u001b[1;34m(docgraph_with_old_names, docgraph_with_new_names)\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[0mold2new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_tok_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_tok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_token_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mold_tok_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_tok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_token_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_tok\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_tok\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# token mismatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             raise ValueError(\n",
        "\u001b[1;31mStopIteration\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mdg.merge_graphs(p.document)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg, layer='mmax')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_pointing_chains(mdg, layer='pocores')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg, layer='pocores'):\n",
      "    print list(p._get_wordlist(chain, verbose=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg, layer='mmax'):\n",
      "    print [(spanstring2text(mdg,mdg.node[node_id]['mmax:span']), node_id) for node_id in chain]        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pocores_chains = get_pointing_chains(mdg, layer='pocores')\n",
      "mmax_chains = get_pointing_chains(mdg, layer='mmax')\n",
      "\n",
      "for chain in mmax_chains:\n",
      "    for node_id in chain:\n",
      "        span_str = mdg.node[node_id]['mmax:span']\n",
      "        markable_was_found = any([token_id in chain\n",
      "                               for token_id in spanstring2tokens(span_str)\n",
      "                               for chain in pocores_chains])\n",
      "        \n",
      "        # at least one word in this markable was found by pocores\n",
      "        markable_str = spanstring2text(mdg, span_str)\n",
      "#         print markable_str, markable_was_found\n",
      "        if not markable_was_found:\n",
      "            markable_was_considered = any(mmax2pocores[mmax_token_id] in p.candidate_report\n",
      "                                          for mmax_token_id in spanstring2tokens(span_str))\n",
      "            if not markable_was_considered:\n",
      "                print (\"No word from the markable '{}' ({} - {}) \"\n",
      "                       \"was even considered as an anaphora\".format(markable_str, node_id, span_str))\n",
      "            else:\n",
      "                for mmax_token_id in spanstring2tokens(span_str):\n",
      "                    if mmax2pocores[mmax_token_id] in p.candidate_report:\n",
      "                        report = p.candidate_report[mmax2pocores[mmax_token_id]]\n",
      "                        if report['anaphora_type'] == 'pronominal':\n",
      "                            print \"Candidate was falsely rejected.\"\n",
      "                            print p.candidate_report[mmax2pocores[mmax_token_id]]\n",
      "        \n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ana in p.candidate_report:\n",
      "    if p.candidate_report[ana]['anaphora_type'] == 'pronominal':\n",
      "        print ana, p.candidate_report[ana]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for chain in get_pointing_chains(mdg):\n",
      "    for node_id in chain:\n",
      "        print node_id, spanstring2text(mdg, mdg.node[node_id]['mmax:span'])\n",
      "        print '\\t', mdg.node[node_id]['mmax:type']\n",
      "    print '\\n'\n",
      "    \n",
      "\n",
      "for chain in get_pointing_chains(p.document):\n",
      "    for node_id in chain:\n",
      "        print node_id,\n",
      "        print '\\t', p.document.node[node_id]['pocores:type']\n",
      "    print '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}