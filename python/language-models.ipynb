{
 "metadata": {
  "name": "",
  "signature": "sha256:0002f37f3b045b8613454cbb77b646b9e81c92b7105c60c0ef3998d1bd23c04b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "from itertools import chain, repeat\n",
      "from language_models.ngrams import ngrams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentences = [\n",
      "    [\"Angie\", \"ist\", \"doof\", \".\"],\n",
      "    [\"Kevin\", \"ist\", \"schlau\", \".\"],\n",
      "    [\"Dies\", \"ist\", \"ein\", \"Test\", \".\"]\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print list(ngrams(sentences[0], 1, pad='<eos>'))\n",
      "print list(ngrams(sentences[0], 2, pad='<eos>'))\n",
      "print list(ngrams(sentences[0], 3, pad='<eos>'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('Angie',), ('ist',), ('doof',), ('.',)]\n",
        "[('Angie', 'ist'), ('ist', 'doof'), ('doof', '.'), ('.', '<eos>')]\n",
        "[('Angie', 'ist', 'doof'), ('ist', 'doof', '.'), ('doof', '.', '<eos>'), ('.', '<eos>', '<eos>')]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 2\n",
      "nc = Counter()\n",
      "for sentence in sentences:\n",
      "    nc.update(ngrams(sentence, n, pad='$'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = 2\n",
      "nc = Counter()\n",
      "for sentence in sentences:\n",
      "    nc.update(ngrams(sentence, n, pad='<eos>'))\n",
      "    \n",
      "print nc # TODO: pad shall always be treated as one symbol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counter({('.', '<eos>'): 3, ('Kevin', 'ist'): 1, ('ist', 'schlau'): 1, ('Dies', 'ist'): 1, ('Angie', 'ist'): 1, ('ist', 'ein'): 1, ('Test', '.'): 1, ('ein', 'Test'): 1, ('doof', '.'): 1, ('schlau', '.'): 1, ('ist', 'doof'): 1})\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_ngram_model(sentences, n, pad='<eos>'):\n",
      "    nc = Counter()\n",
      "    for sentence in sentences:\n",
      "        nc.update(ngrams(sentence, n, pad))\n",
      "    return nc\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "build_ngram_model(sentences, 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "Counter({('.', '<eos>', '<eos>'): 3, ('ist', 'schlau', '.'): 1, ('Test', '.', '<eos>'): 1, ('schlau', '.', '<eos>'): 1, ('ist', 'ein', 'Test'): 1, ('doof', '.', '<eos>'): 1, ('Dies', 'ist', 'ein'): 1, ('Kevin', 'ist', 'schlau'): 1, ('Angie', 'ist', 'doof'): 1, ('ein', 'Test', '.'): 1, ('ist', 'doof', '.'): 1})"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tarfile\n",
      "\n",
      "tar = tarfile.open('/home/arne/corpora/tiger_release_dec05.txt.tar.gz')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Counter()"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger1 = build_ngram_model(tiger_sentences, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.7 s per loop\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger5 = build_ngram_model(tiger_sentences, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.84 s per loop\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Pandas.Series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_ngram_model_pandas(sentences, n, pad='<eos>'):\n",
      "    nc = pandas.Series( list(chain.from_iterable(ngrams(sent, n, pad) for sent in sentences)) )\n",
      "    return nc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger1 = build_ngram_model_pandas(tiger_sentences, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 918 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger5 = build_ngram_model_pandas(tiger_sentences, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 966 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger5 = build_ngram_model_pandas(tiger_sentences, 5)\n",
      "tiger5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "0                (``, Ross, Perot, w\u00e4re, vielleicht)\n",
        "1               (Ross, Perot, w\u00e4re, vielleicht, ein)\n",
        "2         (Perot, w\u00e4re, vielleicht, ein, pr\u00e4chtiger)\n",
        "3      (w\u00e4re, vielleicht, ein, pr\u00e4chtiger, Diktator)\n",
        "4        (vielleicht, ein, pr\u00e4chtiger, Diktator, '')\n",
        "5             (ein, pr\u00e4chtiger, Diktator, '', <eos>)\n",
        "6           (pr\u00e4chtiger, Diktator, '', <eos>, <eos>)\n",
        "7                (Diktator, '', <eos>, <eos>, <eos>)\n",
        "8                   ('', <eos>, <eos>, <eos>, <eos>)\n",
        "9       (Konzernchefs, lehnen, den, Milliard\u00e4r, als)\n",
        "10    (lehnen, den, Milliard\u00e4r, als, US-Pr\u00e4sidenten)\n",
        "11        (den, Milliard\u00e4r, als, US-Pr\u00e4sidenten, ab)\n",
        "12          (Milliard\u00e4r, als, US-Pr\u00e4sidenten, ab, /)\n",
        "13               (als, US-Pr\u00e4sidenten, ab, /, <eos>)\n",
        "14             (US-Pr\u00e4sidenten, ab, /, <eos>, <eos>)\n",
        "...\n",
        "888563                    (Erhalt, der, Nato, ., <eos>)\n",
        "888564                     (der, Nato, ., <eos>, <eos>)\n",
        "888565                   (Nato, ., <eos>, <eos>, <eos>)\n",
        "888566                  (., <eos>, <eos>, <eos>, <eos>)\n",
        "888567        (Der, allein, ist, kein, Zukunftskonzept)\n",
        "888568        (allein, ist, kein, Zukunftskonzept, f\u00fcr)\n",
        "888569           (ist, kein, Zukunftskonzept, f\u00fcr, die)\n",
        "888570    (kein, Zukunftskonzept, f\u00fcr, die, Sicherheit)\n",
        "888571      (Zukunftskonzept, f\u00fcr, die, Sicherheit, in)\n",
        "888572               (f\u00fcr, die, Sicherheit, in, Europa)\n",
        "888573                 (die, Sicherheit, in, Europa, .)\n",
        "888574               (Sicherheit, in, Europa, ., <eos>)\n",
        "888575                    (in, Europa, ., <eos>, <eos>)\n",
        "888576                 (Europa, ., <eos>, <eos>, <eos>)\n",
        "888577                  (., <eos>, <eos>, <eos>, <eos>)\n",
        "Length: 888578, dtype: object"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Counter with list comprehension"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_ngram_model_comprehension(sentences, n, pad='<eos>'):\n",
      "    return Counter( chain.from_iterable(ngrams(sent, n, pad) for sent in sentences) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger1 = build_ngram_model_comprehension(tiger_sentences, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.47 s per loop\n"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger5 = build_ngram_model_comprehension(tiger_sentences, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.61 s per loop\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger5 = build_ngram_model_comprehension(tiger_sentences, 5)\n",
      "tiger5.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "[(('.', '<eos>', '<eos>', '<eos>', '<eos>'), 40091),\n",
        " ((':', '<eos>', '<eos>', '<eos>', '<eos>'), 1439),\n",
        " ((\"''\", '.', '<eos>', '<eos>', '<eos>'), 1348),\n",
        " ((')', '.', '<eos>', '<eos>', '<eos>'), 1335),\n",
        " ((\"''\", '<eos>', '<eos>', '<eos>', '<eos>'), 1157),\n",
        " (('werden', '.', '<eos>', '<eos>', '<eos>'), 1032),\n",
        " (('.', \"''\", '<eos>', '<eos>', '<eos>'), 913),\n",
        " (('?', '<eos>', '<eos>', '<eos>', '<eos>'), 628),\n",
        " (('worden', '.', '<eos>', '<eos>', '<eos>'), 497),\n",
        " ((';', '<eos>', '<eos>', '<eos>', '<eos>'), 477)]"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# cytoolz.frequencies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cytoolz import frequencies\n",
      "\n",
      "def build_ngram_model_cytoolz(sentences, n, pad='<eos>'):\n",
      "    return frequencies( chain.from_iterable(ngrams(sent, n, pad) for sent in sentences) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger1 = build_ngram_model_cytoolz(tiger_sentences, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.17 s per loop\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger5 = build_ngram_model_cytoolz(tiger_sentences, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.31 s per loop\n"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger5 = build_ngram_model_cytoolz(tiger_sentences, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "big = ((k,v) for k, v in tiger5.iteritems() if v > 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in big:\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(('ist', '.', '<eos>', '<eos>', '<eos>'), 302)\n",
        "(('zu', 'haben', '.', '<eos>', '<eos>'), 101)\n",
        "(('hatte', '.', '<eos>', '<eos>', '<eos>'), 159)\n",
        "(('?', '<eos>', '<eos>', '<eos>', '<eos>'), 628)\n",
        "(('ein', '.', '<eos>', '<eos>', '<eos>'), 179)\n",
        "(('nicht', '.', '<eos>', '<eos>', '<eos>'), 173)\n",
        "((\"''\", '.', '<eos>', '<eos>', '<eos>'), 1348)\n",
        "(('kann', '.', '<eos>', '<eos>', '<eos>'), 131)\n",
        "(('wurde', '.', '<eos>', '<eos>', '<eos>'), 145)\n",
        "(('worden', '.', '<eos>', '<eos>', '<eos>'), 497)\n",
        "(('(', 'dpa', ')', '.', '<eos>'), 292)\n",
        "(('mit', '.', '<eos>', '<eos>', '<eos>'), 117)\n",
        "(('k\\xc3\\xb6nnen', '.', '<eos>', '<eos>', '<eos>'), 234)\n",
        "(('hat', '.', '<eos>', '<eos>', '<eos>'), 241)\n",
        "(('/', '<eos>', '<eos>', '<eos>', '<eos>'), 369)\n",
        "((';', '<eos>', '<eos>', '<eos>', '<eos>'), 477)\n",
        "(('dpa', ')', '.', '<eos>', '<eos>'), 354)\n",
        "(('sein', '.', '<eos>', '<eos>', '<eos>'), 297)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "((')', '<eos>', '<eos>', '<eos>', '<eos>'), 352)\n",
        "(('Mark', '.', '<eos>', '<eos>', '<eos>'), 229)\n",
        "(('machen', '.', '<eos>', '<eos>', '<eos>'), 129)\n",
        "(('lassen', '.', '<eos>', '<eos>', '<eos>'), 138)\n",
        "(('.', '<eos>', '<eos>', '<eos>', '<eos>'), 40091)\n",
        "((')', '.', '<eos>', '<eos>', '<eos>'), 1335)\n",
        "(('ab', '.', '<eos>', '<eos>', '<eos>'), 189)\n",
        "(('sei', '.', '<eos>', '<eos>', '<eos>'), 154)\n",
        "(('FRANKFURT', 'A.', 'M.', '<eos>', '<eos>'), 222)\n",
        "(('(', 'rtr', ')', '.', '<eos>'), 101)\n",
        "(('vor', '.', '<eos>', '<eos>', '<eos>'), 157)\n",
        "(('werden', '.', '<eos>', '<eos>', '<eos>'), 1032)\n",
        "(('zu', '.', '<eos>', '<eos>', '<eos>'), 129)\n",
        "(('wird', '.', '<eos>', '<eos>', '<eos>'), 289)\n",
        "(('auf', '.', '<eos>', '<eos>', '<eos>'), 147)\n",
        "(('M.', '<eos>', '<eos>', '<eos>', '<eos>'), 222)\n",
        "((':', '<eos>', '<eos>', '<eos>', '<eos>'), 1439)\n",
        "(('zur\\xc3\\xbcck', '.', '<eos>', '<eos>', '<eos>'), 125)\n",
        "(('(', 'afp', ')', '.', '<eos>'), 127)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(('habe', '.', '<eos>', '<eos>', '<eos>'), 113)\n",
        "(('A.', 'M.', '<eos>', '<eos>', '<eos>'), 222)\n",
        "(('November', '.', '<eos>', '<eos>', '<eos>'), 187)\n",
        "(('aus', '.', '<eos>', '<eos>', '<eos>'), 265)\n",
        "(('Prozent', '.', '<eos>', '<eos>', '<eos>'), 204)\n",
        "(('rtr', ')', '.', '<eos>', '<eos>'), 169)\n",
        "(('an', '.', '<eos>', '<eos>', '<eos>'), 300)\n",
        "(('(', 'ap', ')', '.', '<eos>'), 126)\n",
        "(('haben', '.', '<eos>', '<eos>', '<eos>'), 314)\n",
        "(('afp', ')', '.', '<eos>', '<eos>'), 171)\n",
        "(('soll', '.', '<eos>', '<eos>', '<eos>'), 122)\n",
        "(('war', '.', '<eos>', '<eos>', '<eos>'), 137)\n",
        "(('sind', '.', '<eos>', '<eos>', '<eos>'), 200)\n",
        "((\"''\", '<eos>', '<eos>', '<eos>', '<eos>'), 1157)\n",
        "(('.', \"''\", '<eos>', '<eos>', '<eos>'), 913)\n",
        "(('ap', ')', '.', '<eos>', '<eos>'), 162)\n"
       ]
      }
     ],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from cytoolz import frequencies, concat\n",
      "\n",
      "def build_ngram_model_cytoolz_concat(sentences, n, pad='<eos>'):\n",
      "    return frequencies( concat(ngrams(sent, n, pad) for sent in sentences) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "tiger_sentences = (line.split() for line in tar.extractfile('tiger_release_dec05.txt'))\n",
      "tiger1 = build_ngram_model_cytoolz_concat(tiger_sentences, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.19 s per loop\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}